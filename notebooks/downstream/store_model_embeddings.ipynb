{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3debca1a-1172-4bc8-80b7-4adc63910f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/scratch/sagarsj42')\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/sagarsj42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb17fbc-6cd9-4ebb-9c68-46d9bd2f3ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from bpemb import BPEmb\n",
    "\n",
    "from tri_model import TriModel\n",
    "from trimodal_dataset import CosineSimDatasetWithMD, collate_trimodal_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3abe4329-08bc-4317-b651-c0467460ac99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('weighted-contrastive-embeds', device(type='cuda'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 15\n",
    "EXP_NAME = 'weighted-contrastive'\n",
    "DATASET_INFO_DIR = './yt8m-clips-dataset-info'\n",
    "AUDIO_FEATURES_DIR = './yt8m-audio-features'\n",
    "VIDEO_FEATURES_DIR = './yt8m-video-features'\n",
    "EMB_SIZE = 300\n",
    "BPE_VOCAB_SIZE = 10000\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "EMBEDS_DIR = f'{EXP_NAME}-embeds'\n",
    "# EMBEDS_DIR = 'zeroshot-embeds'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "split = 'test'\n",
    "\n",
    "EMBEDS_DIR, DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4c4d0a-df67-4166-8125-c71104338bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9b15459c10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359665d2-e3d4-4bbc-af84-78208e370926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14806"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bpe_model = BPEmb(lang='en', vs=BPE_VOCAB_SIZE, dim=EMB_SIZE)\n",
    "ds = CosineSimDatasetWithMD(split, DATASET_INFO_DIR, text_bpe_model, \n",
    "            AUDIO_FEATURES_DIR, VIDEO_FEATURES_DIR)\n",
    "\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919bbd8c-76f8-4a3b-878e-2f2bbe969744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1851"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, collate_fn=collate_trimodal_with_metadata, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0514ae9a-7164-49ea-84b8-1cd829880c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_batch', 'audio_batch', 'video_batch', 'vids', 'clip_nos'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(dl))\n",
    "\n",
    "sample_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9a6f0e-cbad-4449-9a97-d855050f258f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1]),\n",
       " torch.Size([8, 384000]),\n",
       " torch.Size([8, 16, 3, 224, 224]),\n",
       " ['ZKBM2XCWfo8',\n",
       "  'ZKBM2XCWfo8',\n",
       "  'ZKBM2XCWfo8',\n",
       "  'ZKBM2XCWfo8',\n",
       "  'ZKBM2XCWfo8',\n",
       "  'ZKBM2XCWfo8',\n",
       "  'ZKBM2XCWfo8',\n",
       "  'ZKBM2XCWfo8'],\n",
       " [21, 20, 22, 23, 27, 26, 18, 24])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['text_batch'].shape, sample_batch['audio_batch'].shape, sample_batch['video_batch'].shape, \\\n",
    "sample_batch['vids'], sample_batch['clip_nos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2bfd54-7b03-47a0-add8-768e78fd113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emb_size': 300,\n",
       " 'bpe_vocab_size': 10000,\n",
       " 'audio_model_key': 'HTSAT-base',\n",
       " 'audio_model_path': 'music_audioset_epoch_15_esc_90.14.pt',\n",
       " 'video_model_key': 'MCG-NJU/videomae-base'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(os.path.join(EXP_NAME, 'best.pth'))\n",
    "model_args = ckpt['model_args']\n",
    "\n",
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5ce164-2606-40e2-b6b9-c113211aa35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TriModel(\n",
       "  (text_model): TextModel(\n",
       "    (model): Sequential(\n",
       "      (0): Embedding(10000, 300)\n",
       "      (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (audio_model): AudioModel(\n",
       "    (encoder): CLAP_Module(\n",
       "      (model): CLAP(\n",
       "        (audio_branch): HTSAT_Swin_Transformer(\n",
       "          (spectrogram_extractor): Spectrogram(\n",
       "            (stft): STFT(\n",
       "              (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "              (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (logmel_extractor): LogmelFilterBank()\n",
       "          (spec_augmenter): SpecAugmentation(\n",
       "            (time_dropper): DropStripes()\n",
       "            (freq_dropper): DropStripes()\n",
       "          )\n",
       "          (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (patch_embed): PatchEmbed(\n",
       "            (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "          (layers): ModuleList(\n",
       "            (0): BasicLayer(\n",
       "              dim=128, input_resolution=(64, 64), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=128, window_size=(8, 8), num_heads=4\n",
       "                    (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=128, window_size=(8, 8), num_heads=4\n",
       "                    (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(64, 64), dim=128\n",
       "                (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicLayer(\n",
       "              dim=256, input_resolution=(32, 32), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=256, window_size=(8, 8), num_heads=8\n",
       "                    (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=256, window_size=(8, 8), num_heads=8\n",
       "                    (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(32, 32), dim=256\n",
       "                (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (2): BasicLayer(\n",
       "              dim=512, input_resolution=(16, 16), depth=12\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (2): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (4): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (5): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (6): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (7): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (8): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (9): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (10): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (11): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(16, 16), dim=512\n",
       "                (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "                (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (3): BasicLayer(\n",
       "              dim=1024, input_resolution=(8, 8), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0-1): 2 x SwinTransformerBlock(\n",
       "                  dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=1024, window_size=(8, 8), num_heads=32\n",
       "                    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "          (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "          (tscam_conv): Conv2d(1024, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "        )\n",
       "        (audio_transform): MLPLayers(\n",
       "          (nonlin): ReLU()\n",
       "          (sequential): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (audio_projection): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (projector): Sequential(\n",
       "      (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (video_model): VideoModel(\n",
       "    (encoder): VideoMAEModel(\n",
       "      (embeddings): VideoMAEEmbeddings(\n",
       "        (patch_embeddings): VideoMAEPatchEmbeddings(\n",
       "          (projection): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "        )\n",
       "      )\n",
       "      (encoder): VideoMAEEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (projector): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=768, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TriModel(**model_args)\n",
    "# model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.to(DEVICE)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "511b1eb4-cd86-4772-be30-e95a2a762fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_emb': tensor([[ 0.1906,  0.4494,  0.0010,  ...,  0.2890, -0.5092,  0.2342],\n",
       "         [ 0.0437,  0.6291, -0.0514,  ...,  0.8207, -0.5110,  0.3962],\n",
       "         [ 0.1707,  0.3814, -0.4413,  ...,  0.6442, -0.2961,  0.3346],\n",
       "         ...,\n",
       "         [ 0.2324,  0.5423,  0.0429,  ...,  0.1731, -0.4147,  0.3479],\n",
       "         [ 0.4373,  0.5902, -0.1453,  ...,  0.5791, -0.4079,  0.2834],\n",
       "         [ 0.3658,  0.6429, -0.0472,  ...,  0.5376, -0.5122,  0.6119]],\n",
       "        device='cuda:0'),\n",
       " 'audio_emb': tensor([[ 0.5166, -0.3874,  0.1859,  ...,  0.0628,  0.0161, -0.3880],\n",
       "         [ 0.3991, -0.5823, -0.1141,  ...,  0.0145,  0.1358, -0.4432],\n",
       "         [ 0.5374, -0.1998,  0.1334,  ..., -0.0272, -0.1605, -0.1940],\n",
       "         ...,\n",
       "         [ 0.5221, -0.6458,  0.1965,  ..., -0.2781, -0.2170, -0.3621],\n",
       "         [ 0.5072, -0.0896, -0.0030,  ..., -0.1893, -0.1466,  0.1588],\n",
       "         [ 0.7991, -0.8976, -0.1543,  ..., -0.4348, -0.1894, -0.3201]],\n",
       "        device='cuda:0'),\n",
       " 'video_emb': tensor([[ 0.0120,  0.5583,  0.2855,  ..., -0.4955,  0.5497,  0.3560],\n",
       "         [ 0.1040,  0.5123,  0.3176,  ..., -0.5191,  0.5466,  0.3703],\n",
       "         [-0.1808,  0.4175,  0.4510,  ..., -0.7035,  0.6136,  0.2424],\n",
       "         ...,\n",
       "         [ 0.0367,  0.5478,  0.2999,  ..., -0.5620,  0.6161,  0.3787],\n",
       "         [-0.0410,  0.4023,  0.4632,  ..., -0.5734,  0.5164,  0.4168],\n",
       "         [-0.0224,  0.5618,  0.4986,  ..., -0.6760,  0.5914,  0.2251]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_batch = {\n",
    "    'text_batch': sample_batch['text_batch'].to(DEVICE),\n",
    "    'audio_batch': sample_batch['audio_batch'].to(DEVICE),\n",
    "    'video_batch': sample_batch['video_batch'].to(DEVICE)\n",
    "}\n",
    "with torch.no_grad():\n",
    "    embeds = model(*inp_batch.values())\n",
    "\n",
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfefe4-daf6-4f4c-bc6d-6c3842e80087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 1851/1851 [40:04<00:00,  1.30s/it]\n",
      "100%|██████████████████████████████████████████████████| 1996/1996 [42:50<00:00,  1.29s/it]\n",
      " 67%|████████████████████████████████▎               | 4953/7356 [1:34:34<48:28,  1.21s/it]"
     ]
    }
   ],
   "source": [
    "for split in ['test', 'dev', 'train']:\n",
    "    ds = CosineSimDatasetWithMD(split, DATASET_INFO_DIR, text_bpe_model, \n",
    "                AUDIO_FEATURES_DIR, VIDEO_FEATURES_DIR)\n",
    "    dl = DataLoader(ds, collate_fn=collate_trimodal_with_metadata, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    os.makedirs(os.path.join(EMBEDS_DIR, split, 'text'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(EMBEDS_DIR, split, 'audio'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(EMBEDS_DIR, split, 'video'), exist_ok=True)\n",
    "\n",
    "    for batch in tqdm(dl):\n",
    "        vids = batch['vids']\n",
    "        clip_nos = batch['clip_nos']\n",
    "        inp_batch = {\n",
    "            'text_batch': batch['text_batch'].to(DEVICE),\n",
    "            'audio_batch': batch['audio_batch'].to(DEVICE),\n",
    "            'video_batch': batch['video_batch'].to(DEVICE)\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeds = model(*inp_batch.values())\n",
    "\n",
    "        for i in range(len(vids)):\n",
    "            vid = vids[i]\n",
    "            clip_no = clip_nos[i]\n",
    "            te = embeds['text_emb'][i, :].cpu().numpy()\n",
    "            ae = embeds['audio_emb'][i, :].cpu().numpy()\n",
    "            ve = embeds['video_emb'][i, :].cpu().numpy()\n",
    "\n",
    "            np.save(os.path.join(EMBEDS_DIR, split, 'text', f'{vid}-{clip_no}-text-emb.npy'), te)\n",
    "            np.save(os.path.join(EMBEDS_DIR, split, 'audio', f'{vid}-{clip_no}-audio-emb.npy'), ae)\n",
    "            np.save(os.path.join(EMBEDS_DIR, split, 'video', f'{vid}-{clip_no}-video-emb.npy'), ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e55b9e-b64c-41ec-825f-2c24769c3da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
