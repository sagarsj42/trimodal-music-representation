{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cce57d2-b854-40ff-9f40-f7a8ddf12439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/scratch/sagarsj42')\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/sagarsj42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab965efb-666a-49f7-8ce2-00e15d8efef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import string\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import VideoMAEModel\n",
    "\n",
    "import laion_clap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bpemb import BPEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb97d7c-a34d-4f90-a8a6-64fc45f0fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/lukewys/laion_clap/resolve/main/music_audioset_epoch_15_esc_90.14.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd3d8bd-de65-4405-beff-837995bdc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INFO_DIR = './yt8m-clips-dataset-info'\n",
    "CLIP_INFO_FILENAME = 'clip-info.jsonl'\n",
    "VID_INFO_FILENAME = 'video-info.jsonl'\n",
    "AUDIO_FEATURES_DIR = './yt8m-audio-features'\n",
    "VIDEO_FEATURES_DIR = './yt8m-video-features'\n",
    "AUDIO_MODEL_KEY = 'HTSAT-base'\n",
    "AUDIO_MODEL_PATH = './music_audioset_epoch_15_esc_90.14.pt'\n",
    "VIDEO_MODEL_KEY = 'MCG-NJU/videomae-base'\n",
    "EMB_SIZE = 300\n",
    "BPE_VOCAB_SIZE = 10000\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "EVAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a849cc-5360-464d-82b4-2c137d74644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2f2751-a054-49d2-a89d-22765cd5bde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 499 entries, 0 to 498\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   vid          499 non-null    object \n",
      " 1   n_clips      499 non-null    int64  \n",
      " 2   audio_dur    499 non-null    float64\n",
      " 3   video_dur    499 non-null    float64\n",
      " 4   split        499 non-null    object \n",
      " 5   labels       499 non-null    object \n",
      " 6   title        499 non-null    object \n",
      " 7   description  499 non-null    object \n",
      " 8   tags         499 non-null    object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 35.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid</th>\n",
       "      <th>n_clips</th>\n",
       "      <th>audio_dur</th>\n",
       "      <th>video_dur</th>\n",
       "      <th>split</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yieL_efMuE0</td>\n",
       "      <td>28</td>\n",
       "      <td>223.376</td>\n",
       "      <td>223.22</td>\n",
       "      <td>dev</td>\n",
       "      <td>[Concert, Musical ensemble]</td>\n",
       "      <td>Goencho Avaz - CIELDA PEREIRA</td>\n",
       "      <td>Herald's Goan Voice - Cielda Pereira\\nMore her...</td>\n",
       "      <td>Joegoauk,goa,cielda,konkani,Lorna,Chris perry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yn_mhi1dDAA</td>\n",
       "      <td>47</td>\n",
       "      <td>371.473</td>\n",
       "      <td>371.29</td>\n",
       "      <td>dev</td>\n",
       "      <td>[Musician, Guitar, String instrument, Acoustic...</td>\n",
       "      <td>Blues Guitar Lick in Minor Pentatonic Scale - ...</td>\n",
       "      <td>Please watch: \"Beginner Acoustic guitar lesson...</td>\n",
       "      <td>Pentatonic Scale,Blues (Musical Genre),Lick,Gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06N2Msd1qUU</td>\n",
       "      <td>26</td>\n",
       "      <td>205.636</td>\n",
       "      <td>205.51</td>\n",
       "      <td>dev</td>\n",
       "      <td>[Music video]</td>\n",
       "      <td>AMV - K-Pop Culture</td>\n",
       "      <td>Music by TAK (https://youtu.be/pftsmKHvlvY)\\n\\...</td>\n",
       "      <td>Culture (Website Category),amv,kpop,k-pop,K-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SI-HfG-y4dU</td>\n",
       "      <td>43</td>\n",
       "      <td>346.105</td>\n",
       "      <td>346.07</td>\n",
       "      <td>dev</td>\n",
       "      <td>[Music video]</td>\n",
       "      <td>DIAURA Lily-sub español</td>\n",
       "      <td>Aqui les dejo un Bonus, Disfrutenlo!  ;)\\n\\nTr...</td>\n",
       "      <td>Diaura (Musical Group),Visual Kei (Musical Genre)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oMaFCb12BMA</td>\n",
       "      <td>21</td>\n",
       "      <td>169.924</td>\n",
       "      <td>169.76</td>\n",
       "      <td>dev</td>\n",
       "      <td>[Music video]</td>\n",
       "      <td>Youtube Rewind INDONESIA 2014</td>\n",
       "      <td>Youtube Rewind Indonesia 2015 https://www.yout...</td>\n",
       "      <td>youtube rewind 2014,youtube rewind indonesia 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vid  n_clips  audio_dur  video_dur split  \\\n",
       "0  yieL_efMuE0       28    223.376     223.22   dev   \n",
       "1  Yn_mhi1dDAA       47    371.473     371.29   dev   \n",
       "2  06N2Msd1qUU       26    205.636     205.51   dev   \n",
       "3  SI-HfG-y4dU       43    346.105     346.07   dev   \n",
       "4  oMaFCb12BMA       21    169.924     169.76   dev   \n",
       "\n",
       "                                              labels  \\\n",
       "0                        [Concert, Musical ensemble]   \n",
       "1  [Musician, Guitar, String instrument, Acoustic...   \n",
       "2                                      [Music video]   \n",
       "3                                      [Music video]   \n",
       "4                                      [Music video]   \n",
       "\n",
       "                                               title  \\\n",
       "0                      Goencho Avaz - CIELDA PEREIRA   \n",
       "1  Blues Guitar Lick in Minor Pentatonic Scale - ...   \n",
       "2                                AMV - K-Pop Culture   \n",
       "3                            DIAURA Lily-sub español   \n",
       "4                      Youtube Rewind INDONESIA 2014   \n",
       "\n",
       "                                         description  \\\n",
       "0  Herald's Goan Voice - Cielda Pereira\\nMore her...   \n",
       "1  Please watch: \"Beginner Acoustic guitar lesson...   \n",
       "2  Music by TAK (https://youtu.be/pftsmKHvlvY)\\n\\...   \n",
       "3  Aqui les dejo un Bonus, Disfrutenlo!  ;)\\n\\nTr...   \n",
       "4  Youtube Rewind Indonesia 2015 https://www.yout...   \n",
       "\n",
       "                                                tags  \n",
       "0  Joegoauk,goa,cielda,konkani,Lorna,Chris perry,...  \n",
       "1  Pentatonic Scale,Blues (Musical Genre),Lick,Gu...  \n",
       "2  Culture (Website Category),amv,kpop,k-pop,K-po...  \n",
       "3  Diaura (Musical Group),Visual Kei (Musical Genre)  \n",
       "4  youtube rewind 2014,youtube rewind indonesia 2...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_df = pd.read_json(os.path.join(DATASET_INFO_DIR, split, VID_INFO_FILENAME), lines=True)\n",
    "\n",
    "print(vid_df.info())\n",
    "\n",
    "vid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451b6b80-00d9-4ca3-9a70-fc7b6fff23bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15961 entries, 0 to 15960\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   vid              15961 non-null  object \n",
      " 1   clip_no          15961 non-null  int64  \n",
      " 2   audio_clip_name  15961 non-null  object \n",
      " 3   audio_clip_dur   15961 non-null  float64\n",
      " 4   video_clip_name  15961 non-null  object \n",
      " 5   video_clip_dur   15961 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 748.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid</th>\n",
       "      <th>clip_no</th>\n",
       "      <th>audio_clip_name</th>\n",
       "      <th>audio_clip_dur</th>\n",
       "      <th>video_clip_name</th>\n",
       "      <th>video_clip_dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yieL_efMuE0</td>\n",
       "      <td>18</td>\n",
       "      <td>yieL_efMuE0-audio-18.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>yieL_efMuE0-video-18.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yieL_efMuE0</td>\n",
       "      <td>24</td>\n",
       "      <td>yieL_efMuE0-audio-24.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>yieL_efMuE0-video-24.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yieL_efMuE0</td>\n",
       "      <td>25</td>\n",
       "      <td>yieL_efMuE0-audio-25.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>yieL_efMuE0-video-25.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yieL_efMuE0</td>\n",
       "      <td>19</td>\n",
       "      <td>yieL_efMuE0-audio-19.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>yieL_efMuE0-video-19.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yieL_efMuE0</td>\n",
       "      <td>27</td>\n",
       "      <td>yieL_efMuE0-audio-27.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>yieL_efMuE0-video-27.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vid  clip_no           audio_clip_name  audio_clip_dur  \\\n",
       "0  yieL_efMuE0       18  yieL_efMuE0-audio-18.mp3             8.0   \n",
       "1  yieL_efMuE0       24  yieL_efMuE0-audio-24.mp3             8.0   \n",
       "2  yieL_efMuE0       25  yieL_efMuE0-audio-25.mp3             8.0   \n",
       "3  yieL_efMuE0       19  yieL_efMuE0-audio-19.mp3             8.0   \n",
       "4  yieL_efMuE0       27  yieL_efMuE0-audio-27.mp3             8.0   \n",
       "\n",
       "            video_clip_name  video_clip_dur  \n",
       "0  yieL_efMuE0-video-18.mp4            8.01  \n",
       "1  yieL_efMuE0-video-24.mp4            8.01  \n",
       "2  yieL_efMuE0-video-25.mp4            8.01  \n",
       "3  yieL_efMuE0-video-19.mp4            8.01  \n",
       "4  yieL_efMuE0-video-27.mp4            8.01  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_df = pd.read_json(os.path.join(DATASET_INFO_DIR, split, CLIP_INFO_FILENAME), lines=True)\n",
    "\n",
    "print(clip_df.info())\n",
    "\n",
    "clip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1ea348c-bc91-4a0b-b4e0-9c3cf46297e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPEmb(lang=en, vs=10000, dim=300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bpe_model = BPEmb(lang='en', vs=BPE_VOCAB_SIZE, dim=EMB_SIZE)\n",
    "\n",
    "text_bpe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "306e29e6-4a88-436f-b545-a3b1deff7753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bpe_model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1175c902-0255-47d4-95bf-124c07af7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimDataset(Dataset):\n",
    "    def __init__(self, split, clips_info_path, text_bpe_model, audio_features_path, video_features_path):\n",
    "        self.split = split\n",
    "        self.clips_info_path = clips_info_path\n",
    "        self.text_bpe_model = text_bpe_model\n",
    "        self.audio_features_path = audio_features_path\n",
    "        self.video_features_path = video_features_path\n",
    "        \n",
    "        self.vid_df = pd.read_json(os.path.join(self.clips_info_path, split, \n",
    "                            'video-info.jsonl'), lines=True)\n",
    "        self.clips_df = pd.read_json(os.path.join(self.clips_info_path, self.split, \n",
    "                            'clip-info.jsonl'), lines=True)\n",
    "        \n",
    "        allowed_text = set(string.ascii_lowercase)\n",
    "        all_texts = list()\n",
    "        for _, row in self.vid_df.iterrows():\n",
    "            text = [t.lower().strip() for t in row['labels'] + row['tags'].split(',')]\n",
    "            text = filter(lambda t: len(t) > 2, text)\n",
    "            text = list(filter(lambda t: set(t) <= set(allowed_text), text))\n",
    "            all_texts.append(text)\n",
    "        self.vid_df['texts'] = all_texts\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.clips_df.shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        clips_row = self.clips_df.iloc[idx]\n",
    "        vid = clips_row['vid']\n",
    "        vid_row = self.vid_df[self.vid_df['vid'] == vid].iloc[0]\n",
    "        split_dir = vid_row['split']\n",
    "        \n",
    "        try:\n",
    "            text = random.choice(vid_row['texts'])\n",
    "            text_ids = np.array(self.text_bpe_model.encode_ids(text))\n",
    "        except IndexError:\n",
    "            text_ids = np.array([0])\n",
    "        audio_clip_filename = clips_row['audio_clip_name']\n",
    "        audio_feat_filename = audio_clip_filename[:-4].replace('-audio-', '-audfeat-') + '.npy'\n",
    "        video_clip_filename = clips_row['video_clip_name']\n",
    "        video_feat_filename = video_clip_filename[:-4].replace('-video-', '-vidfeat-') + '.npy'\n",
    "        audio_feat = np.load(os.path.join(self.audio_features_path, split_dir, vid, audio_feat_filename))\n",
    "        video_feat = np.load(os.path.join(self.video_features_path, split_dir, vid, video_feat_filename))\n",
    "    \n",
    "        return {'text_inp': text_ids, 'audio_inp': audio_feat, 'video_inp': video_feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "176a2279-65ba-43c0-a4c2-3515513f6160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58847, 15961, 14806)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = CosineSimDataset('train', DATASET_INFO_DIR, text_bpe_model, AUDIO_FEATURES_DIR, VIDEO_FEATURES_DIR)\n",
    "dev_ds = CosineSimDataset('dev', DATASET_INFO_DIR, text_bpe_model, AUDIO_FEATURES_DIR, VIDEO_FEATURES_DIR)\n",
    "test_ds = CosineSimDataset('test', DATASET_INFO_DIR, text_bpe_model, AUDIO_FEATURES_DIR, VIDEO_FEATURES_DIR)\n",
    "\n",
    "len(train_ds), len(dev_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8706061c-0ef7-4374-849c-4623b5939924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.88 ms ± 5.15 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_ds[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8365fa31-e4f3-4e15-8687-7f11ce67a7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_inp', 'audio_inp', 'video_inp'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_ds[100]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b37dec-5361-48cb-92ec-0fea5acd8429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112, 126,   6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['text_inp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde168af-fb77-4b3b-aeac-e0f1a961b511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (384001,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample['audio_inp']), sample['audio_inp'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe57eace-3860-4502-a8ca-b8a3f3edd0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (16, 3, 224, 224))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample['video_inp']), sample['video_inp'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83b0bf0d-1997-4255-96fb-0e97e426f1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.array([1, 2]), np.zeros(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae7825cf-6480-4d04-9a0d-6d927eca9985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bpe_model.encode_ids('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22cd8826-31c0-407d-8b9c-06b97b2e090b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', 't', 'a', 'he', 'in', 'the', 'er', 'on', 's']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bpe_model.decode_ids([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d601bd3c-3cec-432d-890a-4bb0cd4f8d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_trimodal_cosine(batch):\n",
    "    texts = list()\n",
    "    audios = list()\n",
    "    videos = list()\n",
    "    max_t = max([len(s['text_inp']) for s in batch])\n",
    "    audio_feats_len = 384000\n",
    "    for sample in batch:\n",
    "        text_ids = sample['text_inp']\n",
    "        pad_len = max_t - len(text_ids)\n",
    "        padded_text_ids = np.concatenate((text_ids, np.zeros(pad_len)))\n",
    "        texts.append(torch.tensor(padded_text_ids, dtype=torch.long).unsqueeze(0))\n",
    "        \n",
    "        audio_feats = sample['audio_inp'][:audio_feats_len]\n",
    "        pad_len = audio_feats_len - len(audio_feats)\n",
    "        padded_audio_feats = np.concatenate((audio_feats, np.zeros(pad_len)))\n",
    "        audios.append(torch.tensor(padded_audio_feats, dtype=torch.float32).unsqueeze(0))\n",
    "        \n",
    "        videos.append(torch.tensor(sample['video_inp'], dtype=torch.float32).unsqueeze(0))\n",
    "    texts = torch.cat(texts, dim=0)\n",
    "    audios = torch.cat(audios, dim=0)\n",
    "    videos = torch.cat(videos, dim=0)\n",
    "    \n",
    "    return {'text_batch': texts, 'audio_batch': audios, 'video_batch': videos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5d94fed-9913-42f3-9e6b-6261154cbfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29424, 3991, 3702)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, collate_fn=collate_trimodal_cosine, \n",
    "                      batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "dev_dl = DataLoader(dev_ds, collate_fn=collate_trimodal_cosine, \n",
    "                      batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, collate_fn=collate_trimodal_cosine, \n",
    "                      batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(train_dl), len(dev_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5791e8d7-b35c-4574-acd1-8cf0ed0a7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_batch', 'audio_batch', 'video_batch'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dl))\n",
    "\n",
    "sample_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08f96c98-e574-4f73-8469-ba9e8571a81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3585],\n",
       "        [1357]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['text_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1782188b-25bc-446d-beb7-28cf8974a195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['audio_batch'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e43f1544-f254-4b0a-bec0-7580dfc397d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 3, 224, 224])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['video_batch'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62e80ae8-f70c-493d-8910-50f40c047f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextModel(\n",
       "  (model): Sequential(\n",
       "    (0): Embedding(10000, 300)\n",
       "    (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=300, out_features=300, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextModel(nn.Module):\n",
    "    def __init__(self, emb_size, bpe_vocab_size):\n",
    "        super(TextModel, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.bpe_vocab_size = bpe_vocab_size\n",
    "        \n",
    "        self.emb_model = BPEmb(lang='en', vs=self.bpe_vocab_size, dim=self.emb_size)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Embedding.from_pretrained(torch.tensor(self.emb_model.vectors)),\n",
    "            nn.LayerNorm(self.emb_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.emb_size, self.emb_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mask = (x != 0) * 1\n",
    "        n_tokens = torch.clamp(mask.sum(dim=1), min=1).unsqueeze(-1)\n",
    "        expanded_mask = mask.unsqueeze(-1).expand(-1, -1, self.emb_size)\n",
    "        \n",
    "        x = self.model(x)\n",
    "        x = x * expanded_mask\n",
    "        x = x.sum(dim=1)\n",
    "        x = x / n_tokens\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "text_model = TextModel(EMB_SIZE, BPE_VOCAB_SIZE)\n",
    "text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fb0f31b-d531-4c13-a7fd-045dfb0f2262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 300]),\n",
       " tensor([[ 0.1430, -0.3933,  0.3621,  0.2887,  0.6107, -0.1417,  0.1118, -0.1488,\n",
       "           0.2626,  0.7315,  0.2968,  0.1911,  0.6233,  0.1070, -0.6465,  0.3091,\n",
       "          -0.6058,  0.0350, -0.0645, -0.0433, -0.0307,  0.3927,  0.5315,  0.2415,\n",
       "          -0.5172, -0.0404, -0.2899,  0.4093,  0.2182,  0.4165,  0.4148, -0.0157,\n",
       "           0.3405, -0.2870,  0.2293,  0.2375, -0.0207,  0.0636, -0.0106, -0.0826,\n",
       "          -0.0438, -0.5452,  0.3489, -0.1245, -0.0946,  0.3676,  0.1745, -0.0524,\n",
       "           0.3004, -0.3933, -0.3097, -0.0125,  0.2758, -0.2303,  0.5781,  0.1127,\n",
       "          -0.2225,  0.4518,  0.5754, -0.6813, -0.5262, -0.0671,  0.3752, -0.5867,\n",
       "          -0.1893, -0.6048, -0.7808,  0.0541,  0.2966, -0.2297, -0.1309, -0.0392,\n",
       "           0.5144, -0.2665, -0.4916, -0.0498, -0.2526,  0.0591,  0.0211,  0.1176,\n",
       "           0.0948, -0.5843,  0.0443,  0.3372, -0.2101, -0.0736, -0.1996,  0.2176,\n",
       "          -0.4355,  0.3781,  0.2783, -0.1091,  0.1149,  0.1552, -0.4517, -0.5486,\n",
       "           0.9553,  0.0579, -0.3686, -0.1625, -0.2415, -0.1380, -0.2919, -0.9479,\n",
       "           0.7034,  0.0523,  0.1817,  0.0118,  0.3951, -0.4023, -0.2462, -0.2109,\n",
       "           0.0461,  0.0927, -0.0752, -0.2279, -0.2382,  0.0660,  0.0678,  0.3397,\n",
       "           0.0065, -0.1428, -0.0810,  0.3938, -0.1421, -0.4765,  0.2601, -0.0664,\n",
       "           0.4621, -0.9769, -0.0233, -0.1613, -0.1941, -0.5642,  0.1831,  0.4971,\n",
       "           0.0555,  0.3791,  0.0962, -0.0904,  0.2800, -0.2407,  0.1052,  0.3355,\n",
       "          -0.4456, -0.8483,  0.2925,  0.0918, -0.0592,  0.5292,  0.6480,  0.5428,\n",
       "          -0.0681,  0.1161,  0.4990,  0.1627,  0.5655, -0.2644,  0.0709, -0.2822,\n",
       "          -0.4050,  0.2914, -0.1202, -0.1197, -0.1379,  0.0780, -0.0653,  0.5563,\n",
       "           0.9131, -0.1361,  0.2514,  0.0698, -0.1601, -0.3398,  0.0087, -0.2695,\n",
       "          -0.4824,  0.1313,  0.4743,  0.0911,  0.1109,  0.4218, -0.1633, -0.2495,\n",
       "           0.3647, -0.4022,  0.4144,  0.2596,  0.1722,  0.0486, -0.4208,  0.0767,\n",
       "           0.0664,  0.3346,  0.1201, -0.3152,  0.2530,  0.3091,  0.2771,  0.3975,\n",
       "           0.1944,  0.1006,  0.0493,  0.0450, -0.0399, -0.2193, -0.3663,  0.4153,\n",
       "          -0.1031, -0.3221,  0.0761, -0.6431, -0.1353,  0.0474,  0.2455,  0.5435,\n",
       "          -0.2390, -0.1528,  0.5909, -0.2471,  0.2561, -0.3305, -0.1814, -0.5984,\n",
       "           0.3586, -0.4680,  0.6464, -0.3263, -0.1286,  0.4555, -0.1419,  0.5290,\n",
       "          -0.3819,  0.1911,  0.1912, -0.1821, -0.1066,  0.4635,  0.3748, -0.0151,\n",
       "           0.1362, -0.0292,  0.1496, -0.5325,  0.0052,  0.5656,  0.0570, -0.1108,\n",
       "           0.3432, -0.1990, -0.1776,  0.1037,  0.1250,  0.0792, -0.3990, -0.5256,\n",
       "          -0.3366,  0.3750, -0.2305,  0.0818, -0.4866, -0.8629,  0.4495,  0.5989,\n",
       "          -0.2546,  0.0635,  0.4922,  0.4362,  0.5315, -0.1509,  0.0457, -0.3384,\n",
       "           0.4186,  0.4408,  0.3471, -0.0345, -0.0353, -0.2322,  0.2815,  0.1447,\n",
       "          -0.3451,  0.1917, -0.2992, -0.6441, -0.2039, -0.2373, -0.5148, -0.4643,\n",
       "          -0.5552,  0.0982, -0.1402,  0.1068,  0.3267,  0.3540,  0.1306, -0.3819,\n",
       "           0.1275, -0.2004,  0.0770, -0.0704],\n",
       "         [-0.2143, -0.0350,  0.6263,  0.2552,  0.6427,  0.3346, -0.0947, -0.1080,\n",
       "           0.0167,  0.1448,  0.3803,  0.2240,  0.6298, -0.4855, -0.2049,  0.2889,\n",
       "          -0.4565, -0.0960, -0.2524,  0.6138, -0.6228,  0.4473,  0.5874,  0.0102,\n",
       "          -0.1176,  0.3933, -0.0316, -0.1994,  0.0436, -0.2033, -0.8281,  0.0241,\n",
       "          -0.1166, -0.5749,  0.9295,  0.1871, -0.0118, -0.1352,  0.7624, -0.2233,\n",
       "           0.0380, -0.1410, -0.1860,  0.1428, -0.4267,  0.7462,  0.0668,  0.2160,\n",
       "           0.5438,  0.0025, -0.2036, -0.4198, -0.3428, -0.2261,  0.4414,  0.0453,\n",
       "          -0.1089,  0.0788,  0.3315, -0.2617, -0.3162,  0.4713,  0.2404,  0.3825,\n",
       "          -0.2302,  0.3777,  0.5046,  0.3262,  0.1450,  0.1138,  0.1261, -0.1863,\n",
       "           0.0654,  0.4502, -0.0403, -0.1895, -0.5574, -0.2486,  0.2951,  0.1307,\n",
       "           0.0059, -0.4269, -0.0328, -0.4334, -0.2331,  0.0432,  0.5085, -0.1044,\n",
       "          -0.2240,  0.0705,  0.1849,  0.1065,  0.0456,  0.6915,  0.0980, -0.5290,\n",
       "           0.3049,  0.0013,  0.5939,  0.1818,  0.0958, -0.4262,  0.0404, -0.1858,\n",
       "          -0.0405,  0.1080, -0.0486, -0.1427, -0.0635,  0.2200, -0.1399,  0.4073,\n",
       "          -0.6226, -0.0583, -0.4037, -0.4453,  0.3801,  0.1998, -0.2781,  0.0926,\n",
       "           0.0903,  0.2266,  0.1751, -0.5726,  0.1922, -0.1698, -0.2696, -0.1143,\n",
       "           0.1422, -0.2351, -0.1783,  0.0535,  0.1443,  0.1259,  0.6875,  0.6831,\n",
       "           0.2109,  0.1736,  0.3221,  0.2867,  0.4189,  0.1478,  0.5885, -0.0640,\n",
       "           0.0351, -0.6047,  0.5028,  0.4473,  0.3788,  0.1280,  0.8677,  0.1949,\n",
       "           0.3604,  0.1095,  0.8028, -0.4154,  0.1503,  0.0970,  0.5073,  0.0182,\n",
       "          -0.1989,  0.3475, -0.0094,  0.1681,  0.1858,  0.2509, -0.0505,  0.0639,\n",
       "           0.1581, -0.2330,  0.1748,  0.0733, -0.1090, -0.4690, -0.0812, -0.1550,\n",
       "          -0.4437, -0.0090,  0.5618,  0.1104,  0.4016, -0.3077, -0.2025,  0.1266,\n",
       "           0.2409,  0.0029, -0.1730, -0.2033, -0.0221,  0.1996, -0.1692,  0.6857,\n",
       "           0.4195, -0.1077,  0.3643,  0.5921, -0.1397,  0.8352, -0.2632,  0.4749,\n",
       "           0.3092, -0.2128,  0.4002,  0.3337, -0.3987, -0.5814,  0.0225, -0.6055,\n",
       "           0.0148, -0.5795,  0.4050, -0.5377, -0.5631,  0.4940,  0.2503,  0.1757,\n",
       "           0.1804,  0.0899,  0.3081, -0.6125, -0.0559,  0.4487, -0.1852, -0.2455,\n",
       "           0.3387, -0.2106,  0.1245, -0.2603,  0.0193,  0.4111, -0.1400,  0.8982,\n",
       "          -0.4391, -0.1013, -0.7043, -0.3644,  0.1065,  0.3550, -0.1013, -0.2008,\n",
       "          -0.1831,  0.5627, -0.2201, -0.3998, -0.1449,  0.1389,  0.2688,  0.1183,\n",
       "           0.8040,  0.7336, -0.3593,  0.3678, -0.3016,  0.1270, -0.1268, -0.3297,\n",
       "          -0.0630, -0.1124, -0.0634, -0.0833, -0.0726, -0.5840,  0.3009,  0.0383,\n",
       "           0.4011, -0.1922,  0.4183, -0.0179,  0.2451,  0.1293, -0.1195,  0.1767,\n",
       "           0.0826,  0.1831,  0.0983, -0.2268,  0.1741, -0.2208, -0.3313,  0.1485,\n",
       "          -0.0784, -0.6397,  0.2737, -0.4605,  0.2296,  0.1918, -0.0898, -0.4204,\n",
       "          -0.1921,  1.1847,  0.2190,  0.2547,  0.2070,  0.3658,  0.1438, -0.1032,\n",
       "          -0.7402, -0.6416,  0.8145,  0.4411]], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emb = text_model(sample_batch['text_batch'])\n",
    "\n",
    "text_emb.shape, text_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f83ce1c-0932-4cc2-938a-aba55b42067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AudioModel(\n",
       "  (encoder): CLAP_Module(\n",
       "    (model): CLAP(\n",
       "      (audio_branch): HTSAT_Swin_Transformer(\n",
       "        (spectrogram_extractor): Spectrogram(\n",
       "          (stft): STFT(\n",
       "            (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "            (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (logmel_extractor): LogmelFilterBank()\n",
       "        (spec_augmenter): SpecAugmentation(\n",
       "          (time_dropper): DropStripes()\n",
       "          (freq_dropper): DropStripes()\n",
       "        )\n",
       "        (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0): BasicLayer(\n",
       "            dim=128, input_resolution=(64, 64), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=128, window_size=(8, 8), num_heads=4\n",
       "                  (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=128, window_size=(8, 8), num_heads=4\n",
       "                  (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(64, 64), dim=128\n",
       "              (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicLayer(\n",
       "            dim=256, input_resolution=(32, 32), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=256, window_size=(8, 8), num_heads=8\n",
       "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=256, window_size=(8, 8), num_heads=8\n",
       "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(32, 32), dim=256\n",
       "              (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (2): BasicLayer(\n",
       "            dim=512, input_resolution=(16, 16), depth=12\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (2): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (3): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (4): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (5): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (6): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (7): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (8): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (9): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (10): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (11): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(16, 16), dim=512\n",
       "              (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (3): BasicLayer(\n",
       "            dim=1024, input_resolution=(8, 8), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=32\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=32\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "        (tscam_conv): Conv2d(1024, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "      )\n",
       "      (audio_transform): MLPLayers(\n",
       "        (nonlin): ReLU()\n",
       "        (sequential): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (audio_projection): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=300, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AudioModel(nn.Module):\n",
    "    def __init__(self, emb_size, audio_model_key, audio_model_path='', quantize_input=True):\n",
    "        super(AudioModel, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.audio_model_key = audio_model_key\n",
    "        self.audio_model_path = audio_model_path\n",
    "        self.quantize = quantize_input\n",
    "        \n",
    "        transformers.logging.set_verbosity_error()\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        self.encoder = laion_clap.CLAP_Module(amodel=self.audio_model_key, enable_fusion=False)\n",
    "        if self.audio_model_path:\n",
    "            self.encoder.load_ckpt(self.audio_model_path)\n",
    "        del self.encoder.model.text_branch\n",
    "        del self.encoder.model.text_transform\n",
    "        del self.encoder.model.text_projection\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        transformers.logging.set_verbosity_warning()\n",
    "        \n",
    "        self.encoder_out_size = self.encoder.model.audio_projection[2].out_features\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.LayerNorm(self.encoder_out_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.encoder_out_size, self.emb_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.quantize:\n",
    "            x = self.int16_to_float32(self.float32_to_int16(x))\n",
    "        x = self.encoder.get_audio_embedding_from_data(x, use_tensor=True)\n",
    "        x = self.projector(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def int16_to_float32(self, x):\n",
    "        return (x / 32767.0).type(torch.float32)\n",
    "\n",
    "    def float32_to_int16(self, x):\n",
    "        x = torch.clamp(x, min=-1., max=1.)\n",
    "        return (x * 32767.).type(torch.int16)\n",
    "\n",
    "\n",
    "audio_model = AudioModel(EMB_SIZE, AUDIO_MODEL_KEY, AUDIO_MODEL_PATH).to('cpu')\n",
    "audio_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81f8422f-58a7-46f3-8342-dc9d88e3ab1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 300]),\n",
       " tensor([[-1.8073e-01, -4.1579e-02, -3.7276e-01, -5.0331e-01, -8.0826e-02,\n",
       "          -5.9152e-01, -3.6822e-01,  3.7489e-01,  5.2272e-01,  2.1830e-01,\n",
       "          -7.8895e-01, -1.5372e-01,  2.6710e-01,  4.1248e-01,  1.2446e-01,\n",
       "          -1.1751e-01,  4.4489e-01, -1.7110e-02,  4.8069e-01, -3.7553e-01,\n",
       "          -4.8587e-01, -2.4678e-01, -2.0443e-02,  7.0252e-02,  1.3200e+00,\n",
       "          -4.3580e-01, -2.4522e-01, -8.6814e-02, -3.1731e-01,  4.1141e-02,\n",
       "           1.6837e-01,  2.9671e-01, -6.6236e-01, -6.5714e-02, -5.2141e-01,\n",
       "          -9.9603e-02, -3.9455e-01,  1.9275e-02, -1.1607e-01, -3.8710e-01,\n",
       "           4.9667e-01,  8.0394e-01,  5.3016e-01,  2.1021e-01, -1.6244e-01,\n",
       "           3.9313e-01, -4.5103e-01,  1.8595e-01,  1.6604e-01, -1.2172e-01,\n",
       "           7.9483e-01,  4.0929e-01,  7.3080e-02, -2.3662e-01, -5.9093e-01,\n",
       "           2.5641e-01, -9.8692e-02,  1.0108e-02, -9.6935e-01, -2.6181e-01,\n",
       "          -7.1860e-01, -4.3967e-01,  1.1687e+00,  6.2672e-01,  5.8343e-02,\n",
       "           4.3012e-01,  1.4738e-01,  2.2221e-01,  3.4289e-01,  9.6595e-02,\n",
       "           1.2792e-01,  1.7556e-01,  2.0658e-01,  1.2736e-01,  8.1808e-01,\n",
       "          -1.3051e-01,  3.4810e-01, -4.9591e-01,  6.7986e-01,  4.3846e-02,\n",
       "          -6.6963e-02, -3.7735e-01,  6.2159e-01, -6.6119e-02, -2.2729e-01,\n",
       "           2.5456e-01,  2.5832e-01, -1.5869e-01, -1.9727e-01,  3.8794e-01,\n",
       "          -5.6217e-04, -4.8776e-01,  4.5425e-01,  1.7823e-01, -4.3199e-01,\n",
       "          -7.3740e-03,  2.6589e-01, -4.3149e-01,  1.1205e+00, -2.5747e-01,\n",
       "          -3.1913e-01,  5.9154e-01, -3.1340e-01,  3.8462e-01,  1.6776e-01,\n",
       "           2.4534e-01,  2.9323e-01, -1.1607e-01, -3.0626e-01, -9.1141e-01,\n",
       "           1.0636e+00,  1.3531e+00, -5.3841e-01,  1.2112e-01,  4.0472e-01,\n",
       "           9.7639e-02, -9.2732e-02, -1.1022e+00,  3.4233e-01, -9.8321e-03,\n",
       "           4.2719e-01, -3.7764e-01, -1.5903e-01,  1.2536e+00, -5.5264e-01,\n",
       "          -2.4018e-01, -1.8312e-01, -4.7821e-01,  6.3950e-02,  5.5361e-02,\n",
       "           4.1000e-01,  3.3069e-01,  8.0024e-01,  1.7184e-01,  7.2325e-02,\n",
       "           1.6992e-01,  9.6248e-01,  5.0068e-01,  9.4820e-02, -1.1408e-01,\n",
       "          -2.7353e-01,  4.4185e-01, -4.6355e-01, -4.5248e-01, -3.6997e-01,\n",
       "           2.7345e-01,  1.5839e-01, -2.5521e-01,  4.0261e-01, -3.0214e-02,\n",
       "           4.3612e-01, -1.4468e-02, -2.1138e-01, -4.6282e-01,  4.5574e-02,\n",
       "           7.8773e-02,  6.2359e-02,  3.7682e-01,  1.8146e-01, -4.1153e-01,\n",
       "          -1.3438e-01, -1.8335e-02, -2.4324e-01,  7.0947e-01,  2.5819e-01,\n",
       "          -2.7156e-01, -6.1500e-01,  1.5860e-01,  2.2548e-01, -6.4436e-01,\n",
       "          -2.2598e-01,  5.7822e-01, -7.5743e-01,  5.8820e-01,  1.2072e-01,\n",
       "          -5.1704e-01, -3.3789e-01,  6.0549e-01,  6.7040e-01, -8.4094e-01,\n",
       "          -5.9322e-01, -1.4320e-01, -4.5336e-01,  2.5135e-01, -4.8999e-01,\n",
       "          -1.1988e-01,  2.2347e-01,  3.7977e-01,  1.4207e-01, -6.4291e-01,\n",
       "          -6.7503e-01, -4.4876e-01,  2.4231e-02,  6.6089e-01,  9.1298e-01,\n",
       "          -9.6097e-01, -3.0527e-01,  3.8822e-01, -1.4189e-01,  6.8996e-01,\n",
       "          -5.7750e-01, -3.8018e-01, -4.6742e-02, -3.8775e-01, -2.7133e-01,\n",
       "           4.5721e-01,  1.5573e-01,  4.1452e-01, -1.9821e-02, -5.6519e-01,\n",
       "          -6.1276e-01,  3.2892e-01,  1.0922e-02,  3.5837e-02,  3.2292e-01,\n",
       "           5.7563e-01, -5.3808e-01, -2.0569e-01, -3.6659e-03, -6.1031e-01,\n",
       "           3.0062e-01, -2.5595e-01,  1.7526e-01,  7.9180e-01, -5.8250e-02,\n",
       "          -3.2911e-01,  1.5104e-01,  2.0508e-01, -2.5255e-01,  2.8201e-01,\n",
       "          -8.5071e-03, -1.2587e-01, -5.4783e-01, -4.8466e-01,  3.6622e-01,\n",
       "           5.1790e-01, -8.9551e-01, -3.0099e-01, -5.5661e-01,  6.2584e-01,\n",
       "          -2.6215e-01,  3.6845e-01,  4.9234e-01, -1.9426e-01, -5.9542e-02,\n",
       "           2.9197e-01,  2.1815e-01, -3.5369e-01, -4.5494e-02, -7.2679e-02,\n",
       "          -6.1992e-02,  5.6768e-01,  4.1879e-01,  4.6219e-01, -6.4558e-01,\n",
       "           1.9503e-01,  1.7696e-01, -1.0694e+00,  6.6123e-01,  4.7726e-01,\n",
       "          -1.2311e-01, -2.1422e-01,  2.2207e-01, -5.7089e-01,  4.6583e-01,\n",
       "          -8.1442e-01,  1.8858e-02, -9.2936e-01, -2.6859e-01,  3.3565e-01,\n",
       "          -2.8131e-01,  4.6742e-01, -3.3481e-01, -3.8860e-01,  1.5561e-01,\n",
       "           3.8600e-01, -3.8340e-01,  1.4483e-01,  2.1658e-01, -1.0124e-01,\n",
       "           4.0747e-01,  1.5774e-01,  4.9064e-01, -2.3349e-01, -2.2812e-01,\n",
       "           2.9495e-01,  2.2476e-01,  1.8634e-01, -3.3005e-01,  1.0049e-01,\n",
       "           1.3330e-01, -2.2200e-01, -4.2982e-01,  1.9022e-03, -6.1207e-01,\n",
       "          -1.2802e-01,  1.6591e-01, -2.2600e-01,  1.2425e-01,  9.6231e-01],\n",
       "         [ 7.0233e-01,  3.3288e-01, -3.1763e-01,  4.9847e-01, -7.7474e-02,\n",
       "           1.6195e-01, -6.2577e-01,  6.2586e-01,  7.3742e-02, -6.2727e-01,\n",
       "          -2.8141e-01, -4.2475e-02,  8.2849e-01, -7.9164e-02, -3.9784e-01,\n",
       "           1.0906e-01,  7.8559e-01,  2.9906e-01,  4.5129e-01,  5.7338e-01,\n",
       "          -4.0355e-01,  2.6558e-01,  5.8652e-02, -3.9811e-01,  5.3978e-01,\n",
       "          -2.3109e-01, -3.7546e-01, -2.8801e-01,  1.7468e-01, -3.0420e-01,\n",
       "           1.9573e-02, -2.5985e-01, -1.9866e-01, -5.9920e-01, -1.0403e+00,\n",
       "           4.4823e-01, -3.6837e-01,  4.7663e-01, -3.0549e-01, -5.1668e-01,\n",
       "           5.7017e-01, -2.9967e-01,  5.1091e-02, -3.3855e-01, -5.1079e-01,\n",
       "          -5.2743e-02, -1.3476e-01, -4.1270e-01,  5.5927e-01, -7.1495e-02,\n",
       "          -3.0972e-01,  3.9110e-01, -2.7821e-01, -4.5627e-01,  3.5028e-01,\n",
       "           6.0150e-01,  4.9005e-01,  6.7665e-02, -6.0042e-02, -1.0699e-01,\n",
       "          -2.7444e-01, -8.8144e-01,  5.9529e-01,  3.0237e-01, -5.9643e-02,\n",
       "          -5.0980e-01,  2.5639e-01,  4.1452e-01,  5.1904e-01,  3.6241e-01,\n",
       "           1.1881e-01,  2.1061e-01,  2.3277e-01, -1.8038e-01,  1.1123e-01,\n",
       "           2.4544e-02,  5.2120e-02, -4.1462e-03,  1.5189e-01, -4.6428e-01,\n",
       "           3.5970e-02, -3.9632e-02,  2.9717e-01,  2.2970e-01, -1.6996e-01,\n",
       "           3.4981e-01,  1.3298e-01,  3.4208e-01, -4.9717e-01, -4.9019e-01,\n",
       "           4.9966e-03,  7.1286e-02, -4.0107e-01, -4.9254e-02, -2.5608e-01,\n",
       "          -1.9004e-01, -2.6431e-01, -1.0057e-01,  3.7387e-01,  9.5991e-02,\n",
       "          -1.4615e-01, -2.4981e-01, -5.1241e-02, -1.6707e-01,  8.5735e-01,\n",
       "           1.6893e-01,  1.8612e-01,  2.1340e-01,  1.0013e-01, -3.1308e-01,\n",
       "           5.0550e-01,  1.3123e+00,  7.9144e-02,  4.3968e-01,  2.1303e-01,\n",
       "          -5.1306e-01,  2.2607e-01, -9.3168e-01,  2.2587e-01, -5.0342e-01,\n",
       "           2.2403e-01, -5.7566e-01, -1.0516e-01,  7.4789e-01,  2.3409e-01,\n",
       "          -4.3380e-02, -7.1282e-02,  1.0525e-01,  6.2298e-01, -9.7437e-01,\n",
       "           2.6400e-01,  5.0913e-01, -7.5571e-02,  1.9687e-01, -5.4046e-02,\n",
       "           6.9852e-01,  2.1026e-01,  5.1331e-01, -4.4705e-01, -5.0417e-01,\n",
       "           2.2646e-01,  3.1059e-01, -8.6319e-02, -5.9611e-01, -3.6756e-01,\n",
       "          -3.1282e-01,  3.3506e-01,  1.7988e-01,  2.9158e-01,  1.4052e-01,\n",
       "          -3.6249e-01, -3.6112e-01,  5.1542e-01, -1.0681e+00,  4.0273e-01,\n",
       "           3.8681e-01, -6.7429e-01, -1.0468e-01,  5.7895e-01, -1.0540e-01,\n",
       "           2.1866e-01, -2.2604e-01,  4.8660e-01,  4.1420e-01,  2.4597e-01,\n",
       "           2.7288e-01, -3.2506e-01,  2.1946e-01,  7.2581e-01, -7.5565e-01,\n",
       "           1.3662e-01, -3.0504e-01, -9.3122e-02,  5.1557e-01,  5.2438e-02,\n",
       "           1.1858e-01, -6.5566e-01,  2.5104e-02,  6.8439e-02, -1.6935e-01,\n",
       "           2.3959e-01, -2.6908e-01,  1.1277e-01,  7.0199e-01, -4.6419e-01,\n",
       "          -1.4265e-01,  1.8219e-01,  9.1429e-04, -7.8016e-02,  8.7636e-01,\n",
       "          -3.0655e-01, -5.5010e-01,  1.5426e-01, -2.6272e-01,  7.5914e-01,\n",
       "          -6.3335e-01,  2.4984e-02, -2.4471e-01, -2.0637e-01,  1.3430e+00,\n",
       "          -7.2659e-02, -3.5550e-01, -7.2068e-01, -1.4631e-01,  5.2353e-01,\n",
       "           2.3472e-01, -5.3775e-01, -4.5672e-01,  1.6149e-01,  1.7590e-01,\n",
       "          -6.8771e-01,  3.2536e-01,  4.6677e-01,  9.9326e-02, -5.3114e-01,\n",
       "           3.3862e-01, -1.1547e-01,  3.6684e-01, -9.5568e-02, -6.9832e-01,\n",
       "          -5.7569e-01, -3.8309e-01,  1.3677e-01,  4.0346e-02, -3.1733e-01,\n",
       "          -2.0603e-01, -1.1767e-02, -2.2138e-01, -5.0136e-01, -3.0910e-01,\n",
       "           3.0416e-01,  3.6571e-01, -1.2348e-01,  2.3814e-01, -5.2880e-01,\n",
       "           1.1976e+00,  1.6113e-01, -1.0213e-01, -3.3135e-01,  2.7331e-01,\n",
       "          -2.7843e-01,  2.7788e-03, -2.1787e-01, -2.0978e-01, -3.6125e-01,\n",
       "          -5.3652e-01, -3.0360e-01, -2.5760e-01,  2.0839e-01,  1.7112e-01,\n",
       "          -2.6334e-01,  2.5339e-01,  7.4029e-01,  2.6364e-01,  1.6093e-01,\n",
       "          -4.6297e-01,  2.3208e-01, -5.4014e-01, -6.0852e-02,  5.5236e-01,\n",
       "           2.3515e-01, -9.9503e-01,  1.0599e-01, -1.0480e+00,  1.0433e-01,\n",
       "          -7.3843e-01,  3.4675e-01, -2.7159e-01, -3.3545e-01,  1.9930e-01,\n",
       "          -9.1956e-01,  3.3688e-02,  1.8596e-01, -4.8172e-01, -3.1690e-01,\n",
       "          -7.3915e-01, -3.0553e-01,  4.3509e-01, -1.9015e-01,  5.8674e-01,\n",
       "          -8.8639e-01,  6.0194e-01,  7.5476e-01,  2.3820e-01, -4.3357e-01,\n",
       "           6.3924e-01,  5.4536e-01,  7.5312e-01, -1.0308e-01, -7.2537e-02,\n",
       "          -3.5958e-01,  4.0654e-01,  3.4259e-01, -1.4717e-01, -3.0835e-01,\n",
       "          -1.7811e-01,  5.1685e-01,  3.1684e-01,  1.7905e-01,  4.8643e-01]],\n",
       "        grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb = audio_model(sample_batch['audio_batch'])\n",
    "\n",
    "audio_emb.shape, audio_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6476b86c-ef24-4914-9eae-bb85756cdebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoModel(\n",
       "  (encoder): VideoMAEModel(\n",
       "    (embeddings): VideoMAEEmbeddings(\n",
       "      (patch_embeddings): VideoMAEPatchEmbeddings(\n",
       "        (projection): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "      )\n",
       "    )\n",
       "    (encoder): VideoMAEEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (6): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (7): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (8): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (9): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (10): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (11): VideoMAELayer(\n",
       "          (attention): VideoMAEAttention(\n",
       "            (attention): VideoMAESelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): VideoMAESelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VideoMAEIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VideoMAEOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=300, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VideoModel(nn.Module):\n",
    "    def __init__(self, emb_size, video_model_key):\n",
    "        super(VideoModel, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.video_model_key = video_model_key\n",
    "        \n",
    "        transformers.logging.set_verbosity_error()\n",
    "        self.encoder = VideoMAEModel.from_pretrained(self.video_model_key)\n",
    "        self.encoder_out_size = self.encoder.config.hidden_size\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.LayerNorm(self.encoder_out_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.encoder_out_size, self.emb_size)\n",
    "        )\n",
    "        transformers.logging.set_verbosity_warning()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(pixel_values=x).last_hidden_state\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.projector(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "video_model = VideoModel(EMB_SIZE, VIDEO_MODEL_KEY)\n",
    "video_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b76c222-fb90-44a3-96db-48c9ba00ecd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 300]),\n",
       " tensor([[-0.5772, -0.3672, -0.9825,  0.0232, -0.2266,  0.0496, -1.2599,  0.6325,\n",
       "           0.2771,  0.2600, -0.2905, -0.2857, -1.2756,  0.9483, -0.8149, -0.0745,\n",
       "           0.6951,  0.6323, -0.2415, -0.4669, -1.0633,  0.2361, -0.4361,  1.0861,\n",
       "          -0.3240, -0.3145, -0.2219,  0.7223, -0.2788,  1.2020, -0.1038,  1.2844,\n",
       "          -0.6843,  0.7090, -0.2504, -0.5071, -1.0594, -0.6429, -0.9707, -0.5802,\n",
       "           0.0932, -0.7462,  0.9548, -0.4646,  0.1008, -0.4022, -0.2463, -0.5239,\n",
       "          -0.7948, -1.2660,  0.5816, -0.1840, -0.2004, -0.1838, -0.2320, -0.4598,\n",
       "          -1.2962, -0.9520, -0.9570,  0.6878, -0.6147, -0.5386,  0.8518, -0.3208,\n",
       "          -0.1727, -0.1498,  0.1091,  0.4571,  0.0142, -0.4953,  0.8885, -0.1491,\n",
       "          -0.9241, -0.0977,  0.3356, -1.0355, -0.0832,  0.0390,  1.3734, -0.4376,\n",
       "           0.9956,  0.5463,  0.9985, -1.2804,  0.8385,  0.3050, -0.0207,  0.1187,\n",
       "           0.1019,  0.0126,  0.6233,  0.9568, -0.6971, -0.0622,  1.2899,  0.2063,\n",
       "           0.5233,  0.2892,  1.0255,  0.3610,  0.9122, -1.0614,  0.3484,  0.2844,\n",
       "           1.0340, -0.5665, -0.6472,  0.7566, -1.0571, -0.0585, -0.9365,  0.2840,\n",
       "           0.0660,  0.1162, -0.6492, -1.1273,  1.0068,  0.6532, -0.5667, -1.0207,\n",
       "           1.2970, -0.8301,  1.1824, -0.4874,  0.9167,  0.3819,  0.2499,  0.6743,\n",
       "           0.4861, -1.3770, -1.0202, -0.7591,  1.0067,  0.4828, -0.6431,  0.2500,\n",
       "          -0.8469, -0.4178,  0.6487, -0.7448, -0.2617,  0.1171, -1.2932,  0.0760,\n",
       "           0.6266,  0.0022, -0.2162,  0.4069,  1.2998,  0.4184, -0.7837,  0.7511,\n",
       "           0.5385, -0.6827, -0.2762, -0.0171,  0.1396, -0.1465, -0.6397, -0.4426,\n",
       "           0.6431,  0.2999, -0.5091,  1.4322,  0.1567,  0.5815, -0.6082,  0.6946,\n",
       "          -0.4168,  0.9853, -0.9614, -0.3213, -0.6238, -1.0390, -0.2658, -1.2785,\n",
       "          -0.4371, -0.0781, -0.5404, -0.2394,  0.6860,  0.1567,  0.7517, -0.0422,\n",
       "          -0.8889,  0.5614, -1.0197, -0.4985,  0.1140,  0.2387, -0.6003,  0.8031,\n",
       "           1.3192,  0.4303, -0.0995, -0.1251, -1.1717, -0.2711, -0.3907,  0.7142,\n",
       "          -0.7568,  0.5656, -0.7456,  0.4707,  0.5301, -0.2144, -0.7520, -0.5263,\n",
       "           0.9234, -1.1221, -1.0723,  0.8394,  0.2276, -0.8270,  1.1207,  0.1690,\n",
       "           0.8915, -0.6737,  1.2127,  1.1643, -1.0678, -0.3770, -0.3583,  0.5808,\n",
       "           0.8623,  1.1077,  0.8941, -0.3803,  1.2608,  0.9754,  0.6587,  1.0897,\n",
       "          -0.6571, -0.2961, -0.3089,  0.4033,  1.1721, -0.9243,  0.0373, -0.6976,\n",
       "          -0.2976, -1.1632, -0.8909, -0.6504,  0.7967,  0.3875,  0.9328,  0.7847,\n",
       "          -0.7994,  0.0323, -0.0348, -0.7203,  1.0526,  1.3613, -1.0106,  0.1884,\n",
       "          -0.1850, -0.0736, -0.4260,  0.3186, -0.8797, -0.5261,  0.6997,  0.9133,\n",
       "          -0.5236, -0.6655, -0.7178, -0.1714, -0.4147, -0.5277, -0.3464, -0.8196,\n",
       "           0.3382, -0.4614,  0.0956,  0.7752,  0.4338, -0.0986, -0.1615, -1.0527,\n",
       "           1.0296, -0.0812,  1.1712, -0.0804,  0.0883, -0.8257,  0.8966,  0.9741,\n",
       "          -0.6934, -0.6720,  0.1741,  0.6729, -0.6732, -0.2496,  0.8167,  0.5698,\n",
       "          -0.0551,  0.4048, -0.2939,  0.6790],\n",
       "         [-0.5848, -0.2723, -1.0903, -0.2966, -0.1355,  0.0592, -1.2596,  0.9722,\n",
       "           0.1613,  0.4113, -0.1548, -0.1008, -1.1170,  0.9009, -0.9477,  0.0874,\n",
       "           0.7393,  0.8530, -0.2825, -0.1002, -0.9725,  0.1718, -0.2905,  0.9360,\n",
       "          -0.5024, -0.3976, -0.1815,  0.3494, -0.1953,  1.0085, -0.3213,  1.1103,\n",
       "          -0.5286,  0.5957, -0.2481, -0.6302, -1.1463, -0.3968, -0.8033, -0.6405,\n",
       "          -0.0836, -0.4244,  0.9585, -0.7116,  0.1489, -0.4125, -0.2495, -0.5118,\n",
       "          -0.3767, -1.1602,  0.6057, -0.1272, -0.1233, -0.1478, -0.2073, -0.3739,\n",
       "          -1.1763, -0.9843, -0.8524,  0.7685, -0.9078, -0.5334,  0.9720, -0.2848,\n",
       "          -0.3803, -0.3589, -0.1794,  0.6200,  0.0409, -0.4965,  0.8195, -0.2235,\n",
       "          -1.0257, -0.0504,  0.4549, -0.9647, -0.2796,  0.0361,  1.2064, -0.2819,\n",
       "           1.0243,  0.7557,  0.9658, -1.0692,  0.9483,  0.1584,  0.0195,  0.2062,\n",
       "           0.4220,  0.2787,  0.6717,  0.8662, -0.5948, -0.3400,  1.2005,  0.0651,\n",
       "           0.5459,  0.1619,  0.8213,  0.6615,  0.8830, -1.1753,  0.3544,  0.0275,\n",
       "           0.8764, -0.6984, -0.6091,  0.6367, -0.9079,  0.2395, -0.7572,  0.5044,\n",
       "           0.1930,  0.2719, -0.7312, -1.2495,  0.9561,  0.7067, -0.4840, -1.0837,\n",
       "           1.0075, -0.6927,  0.9238, -0.6407,  0.8457,  0.5128,  0.5496,  0.5751,\n",
       "           0.2700, -1.1339, -0.9928, -0.7872,  1.0262,  0.7121, -0.8119,  0.3059,\n",
       "          -0.7009, -0.5428,  0.7492, -0.5602,  0.0452,  0.1813, -1.2066, -0.0697,\n",
       "           0.8545,  0.0747, -0.3527,  0.3678,  1.0410,  0.3049, -0.7711,  0.4036,\n",
       "           0.2540, -0.7239, -0.1673, -0.1231, -0.1535, -0.2430, -0.8610, -0.5046,\n",
       "           0.9711,  0.5279, -0.5479,  1.3086,  0.3172,  0.8006, -0.6453,  0.7892,\n",
       "          -0.3030,  0.9778, -1.0727, -0.3221, -0.5214, -1.1167, -0.3073, -1.2314,\n",
       "          -0.2192,  0.1035, -0.3363, -0.2168,  0.4471,  0.4562,  0.5401, -0.0451,\n",
       "          -1.0595,  0.6940, -1.0076, -0.5796, -0.0593,  0.0438, -0.8118,  0.7368,\n",
       "           1.0992,  0.4377, -0.1757, -0.0539, -1.0072, -0.5982, -0.5779,  0.6181,\n",
       "          -0.8472,  0.9609, -0.7418,  0.3788,  0.4391, -0.5363, -0.9178, -0.4480,\n",
       "           0.7784, -1.1171, -1.1256,  0.9911,  0.0026, -0.8430,  1.0379,  0.3939,\n",
       "           0.8711, -0.7855,  1.1670,  1.2190, -1.0875, -0.4168, -0.3923,  1.0933,\n",
       "           1.0391,  0.8694,  1.1944, -0.4324,  1.2538,  0.9602,  0.6895,  1.1286,\n",
       "          -0.8085, -0.4902, -0.0166,  0.0948,  0.8650, -0.6344,  0.2013, -0.8551,\n",
       "          -0.3360, -1.1334, -0.7828, -0.4007,  0.8998,  0.1381,  0.8705,  0.9162,\n",
       "          -0.9280,  0.0943,  0.0698, -0.8652,  0.7507,  1.1974, -0.7749,  0.0934,\n",
       "          -0.0817, -0.0173, -0.4924,  0.4485, -0.9428, -0.9319,  0.8298,  0.6441,\n",
       "          -0.5538, -0.6799, -0.7166, -0.2734, -0.3095, -0.4107, -0.7474, -0.6762,\n",
       "           0.4989, -0.8604,  0.0656,  0.9150,  0.4941, -0.1481, -0.2263, -0.8786,\n",
       "           0.8913, -0.0664,  0.9562, -0.0874,  0.1482, -0.6790,  0.8808,  1.0463,\n",
       "          -0.8267, -1.0500,  0.5294,  1.0295, -0.5899, -0.4188,  0.7386,  0.7027,\n",
       "          -0.3210,  0.4991,  0.0565,  0.8059]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    video_emb = video_model(sample_batch['video_batch'])\n",
    "\n",
    "video_emb.shape, video_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "544204bc-1d80-4e35-b8f9-74ec63c7ab1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriModel(\n",
       "  (text_model): TextModel(\n",
       "    (model): Sequential(\n",
       "      (0): Embedding(10000, 300)\n",
       "      (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (audio_model): AudioModel(\n",
       "    (encoder): CLAP_Module(\n",
       "      (model): CLAP(\n",
       "        (audio_branch): HTSAT_Swin_Transformer(\n",
       "          (spectrogram_extractor): Spectrogram(\n",
       "            (stft): STFT(\n",
       "              (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "              (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (logmel_extractor): LogmelFilterBank()\n",
       "          (spec_augmenter): SpecAugmentation(\n",
       "            (time_dropper): DropStripes()\n",
       "            (freq_dropper): DropStripes()\n",
       "          )\n",
       "          (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (patch_embed): PatchEmbed(\n",
       "            (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "          (layers): ModuleList(\n",
       "            (0): BasicLayer(\n",
       "              dim=128, input_resolution=(64, 64), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=128, window_size=(8, 8), num_heads=4\n",
       "                    (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=128, window_size=(8, 8), num_heads=4\n",
       "                    (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(64, 64), dim=128\n",
       "                (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicLayer(\n",
       "              dim=256, input_resolution=(32, 32), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=256, window_size=(8, 8), num_heads=8\n",
       "                    (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=256, window_size=(8, 8), num_heads=8\n",
       "                    (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(32, 32), dim=256\n",
       "                (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (2): BasicLayer(\n",
       "              dim=512, input_resolution=(16, 16), depth=12\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (2): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (4): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (5): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (6): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (7): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (8): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (9): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (10): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (11): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(16, 16), dim=512\n",
       "                (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "                (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (3): BasicLayer(\n",
       "              dim=1024, input_resolution=(8, 8), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=1024, window_size=(8, 8), num_heads=32\n",
       "                    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=1024, window_size=(8, 8), num_heads=32\n",
       "                    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "          (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "          (tscam_conv): Conv2d(1024, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "        )\n",
       "        (audio_transform): MLPLayers(\n",
       "          (nonlin): ReLU()\n",
       "          (sequential): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (audio_projection): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (projector): Sequential(\n",
       "      (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (video_model): VideoModel(\n",
       "    (encoder): VideoMAEModel(\n",
       "      (embeddings): VideoMAEEmbeddings(\n",
       "        (patch_embeddings): VideoMAEPatchEmbeddings(\n",
       "          (projection): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "        )\n",
       "      )\n",
       "      (encoder): VideoMAEEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (6): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (7): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (8): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (9): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (10): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (11): VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (projector): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=768, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TriModel(nn.Module):\n",
    "    def __init__(self, emb_size, bpe_vocab_size, audio_model_key, \n",
    "                 audio_model_path, video_model_key):\n",
    "        \n",
    "        super(TriModel, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.bpe_vocab_size = bpe_vocab_size\n",
    "        self.audio_model_key = audio_model_key\n",
    "        self.audio_model_path = audio_model_path\n",
    "        self.video_model_key = video_model_key\n",
    "        \n",
    "        self.text_model = TextModel(self.emb_size, self.bpe_vocab_size)\n",
    "        self.audio_model = AudioModel(self.emb_size, self.audio_model_key, self.audio_model_path, \n",
    "                              quantize_input=True).to('cpu')\n",
    "        self.video_model = VideoModel(self.emb_size, self.video_model_key)\n",
    "    \n",
    "    def forward(self, t_x, a_x, v_x):\n",
    "        t_x = self.text_model(t_x)\n",
    "        a_x = self.audio_model(a_x)\n",
    "        v_x = self.video_model(v_x)\n",
    "        \n",
    "        return {'text_emb': t_x, 'audio_emb': a_x, 'video_emb': v_x}\n",
    "\n",
    "\n",
    "trimodel = TriModel(EMB_SIZE, BPE_VOCAB_SIZE, AUDIO_MODEL_KEY, AUDIO_MODEL_PATH, VIDEO_MODEL_KEY).to('cpu')\n",
    "trimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ee885fc-30bf-42f2-9009-85b844aef7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_emb', 'audio_emb', 'video_emb'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embeds = trimodel(*sample_batch.values())\n",
    "\n",
    "embeds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "094881d4-11e3-43fa-add1-91861b639e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 300]), torch.Size([2, 300]), torch.Size([2, 300]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds['text_emb'].shape, embeds['audio_emb'].shape, embeds['video_emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7d20a36-9366-41a6-9673-34f507b0cdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params\n",
      "text model: 3090900\n",
      "audio model: 73892229\n",
      "video model: 86459436\n",
      "tri model: 163442565\n"
     ]
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    n_params = 0\n",
    "    for p in model.parameters():\n",
    "        n_params += p.numel()\n",
    "    \n",
    "    return n_params\n",
    "\n",
    "print('# params')\n",
    "print('text model:', get_n_params(text_model))\n",
    "print('audio model:', get_n_params(audio_model))\n",
    "print('video model:', get_n_params(video_model))\n",
    "print('tri model:', get_n_params(trimodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbc5da1f-f7bb-4165-8d01-33be6968aaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CosineEmbeddingLoss()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CosineEmbeddingLoss()\n",
    "\n",
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "60a06f96-e80d-4935-b8e1-a6cff0498334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_dissim_objective(embeds):\n",
    "    te = embeds['text_emb']\n",
    "    ae = embeds['audio_emb']\n",
    "    ve = embeds['video_emb']\n",
    "    bs = te.shape[0]\n",
    "    bs_h = bs // 2\n",
    "    pos_targets = torch.ones(bs)\n",
    "    neg_targets = torch.ones(bs_h) * -1\n",
    "    criterion = nn.CosineEmbeddingLoss(margin=0.0, reduction='mean')\n",
    "    \n",
    "    cos_loss = 0\n",
    "    cos_loss += criterion(te, ae, pos_targets) + criterion(te, ve, pos_targets) + criterion(ae, ve, pos_targets)\n",
    "    cos_loss += criterion(te[:bs_h, :], ae[bs_h:, :], neg_targets) + \\\n",
    "        criterion(te[bs_h:, :], ae[:bs_h, :], neg_targets)\n",
    "    cos_loss += criterion(te[:bs_h, :], ve[bs_h:, :], neg_targets) + \\\n",
    "        criterion(te[bs_h:, :], ve[:bs_h, :], neg_targets)\n",
    "    cos_loss += criterion(ae[:bs_h, :], ve[bs_h:, :], neg_targets) + \\\n",
    "        criterion(ae[bs_h:, :], ve[:bs_h, :], neg_targets)\n",
    "    \n",
    "    return cos_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9023fe4e-d5c4-4649-a81c-a3fbd0d2d785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2567)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_dissim_objective(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02820130-0600-4896-99a7-b10ac033a06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
