{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cce57d2-b854-40ff-9f40-f7a8ddf12439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/scratch/sagarsj42')\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/sagarsj42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab965efb-666a-49f7-8ce2-00e15d8efef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import string\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from bpemb import BPEmb\n",
    "\n",
    "from tri_model import TriModel\n",
    "from trimodal_dataset import CosineSimDataset, collate_trimodal_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb97d7c-a34d-4f90-a8a6-64fc45f0fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/lukewys/laion_clap/resolve/main/music_audioset_epoch_15_esc_90.14.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd3d8bd-de65-4405-beff-837995bdc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INFO_DIR = './yt8m-clips-dataset-info'\n",
    "CLIP_INFO_FILENAME = 'clip-info.jsonl'\n",
    "VID_INFO_FILENAME = 'video-info.jsonl'\n",
    "AUDIO_FEATURES_DIR = './yt8m-audio-features'\n",
    "VIDEO_FEATURES_DIR = './yt8m-video-features'\n",
    "AUDIO_MODEL_KEY = 'HTSAT-base'\n",
    "AUDIO_MODEL_PATH = './music_audioset_epoch_15_esc_90.14.pt'\n",
    "VIDEO_MODEL_KEY = 'MCG-NJU/videomae-base'\n",
    "EMB_SIZE = 300\n",
    "BPE_VOCAB_SIZE = 10000\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "EVAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3a849cc-5360-464d-82b4-2c137d74644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ea348c-bc91-4a0b-b4e0-9c3cf46297e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPEmb(lang=en, vs=10000, dim=300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bpe_model = BPEmb(lang='en', vs=BPE_VOCAB_SIZE, dim=EMB_SIZE)\n",
    "\n",
    "text_bpe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176a2279-65ba-43c0-a4c2-3515513f6160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58847, 15961, 14806)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = CosineSimDataset('train', DATASET_INFO_DIR, text_bpe_model, AUDIO_FEATURES_DIR, VIDEO_FEATURES_DIR)\n",
    "dev_ds = CosineSimDataset('dev', DATASET_INFO_DIR, text_bpe_model, AUDIO_FEATURES_DIR, VIDEO_FEATURES_DIR)\n",
    "test_ds = CosineSimDataset('test', DATASET_INFO_DIR, text_bpe_model, AUDIO_FEATURES_DIR, VIDEO_FEATURES_DIR)\n",
    "\n",
    "len(train_ds), len(dev_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8706061c-0ef7-4374-849c-4623b5939924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81 ms ± 6.16 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_ds[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8365fa31-e4f3-4e15-8687-7f11ce67a7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_inp', 'audio_inp', 'video_inp'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_ds[100]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b37dec-5361-48cb-92ec-0fea5acd8429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 216, 8401, 9918])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['text_inp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde168af-fb77-4b3b-aeac-e0f1a961b511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (384001,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample['audio_inp']), sample['audio_inp'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe57eace-3860-4502-a8ca-b8a3f3edd0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (16, 3, 224, 224))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample['video_inp']), sample['video_inp'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b0bf0d-1997-4255-96fb-0e97e426f1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.array([1, 2]), np.zeros(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae7825cf-6480-4d04-9a0d-6d927eca9985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bpe_model.encode_ids('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22cd8826-31c0-407d-8b9c-06b97b2e090b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', 't', 'a', 'he', 'in', 'the', 'er', 'on', 's']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bpe_model.decode_ids([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d94fed-9913-42f3-9e6b-6261154cbfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29424, 3991, 3702)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, collate_fn=collate_trimodal_cosine, \n",
    "                      batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "dev_dl = DataLoader(dev_ds, collate_fn=collate_trimodal_cosine, \n",
    "                      batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, collate_fn=collate_trimodal_cosine, \n",
    "                      batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(train_dl), len(dev_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5791e8d7-b35c-4574-acd1-8cf0ed0a7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_batch', 'audio_batch', 'video_batch'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dl))\n",
    "\n",
    "sample_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08f96c98-e574-4f73-8469-ba9e8571a81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2023, 7196],\n",
       "        [  27, 5684]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['text_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1782188b-25bc-446d-beb7-28cf8974a195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['audio_batch'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e43f1544-f254-4b0a-bec0-7580dfc397d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 3, 224, 224])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['video_batch'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "544204bc-1d80-4e35-b8f9-74ec63c7ab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TriModel(\n",
       "  (text_model): TextModel(\n",
       "    (model): Sequential(\n",
       "      (0): Embedding(10000, 300)\n",
       "      (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (audio_model): AudioModel(\n",
       "    (encoder): CLAP_Module(\n",
       "      (model): CLAP(\n",
       "        (audio_branch): HTSAT_Swin_Transformer(\n",
       "          (spectrogram_extractor): Spectrogram(\n",
       "            (stft): STFT(\n",
       "              (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "              (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (logmel_extractor): LogmelFilterBank()\n",
       "          (spec_augmenter): SpecAugmentation(\n",
       "            (time_dropper): DropStripes()\n",
       "            (freq_dropper): DropStripes()\n",
       "          )\n",
       "          (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (patch_embed): PatchEmbed(\n",
       "            (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "          (layers): ModuleList(\n",
       "            (0): BasicLayer(\n",
       "              dim=128, input_resolution=(64, 64), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=128, window_size=(8, 8), num_heads=4\n",
       "                    (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=128, window_size=(8, 8), num_heads=4\n",
       "                    (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(64, 64), dim=128\n",
       "                (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicLayer(\n",
       "              dim=256, input_resolution=(32, 32), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=256, window_size=(8, 8), num_heads=8\n",
       "                    (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=256, window_size=(8, 8), num_heads=8\n",
       "                    (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(32, 32), dim=256\n",
       "                (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (2): BasicLayer(\n",
       "              dim=512, input_resolution=(16, 16), depth=12\n",
       "              (blocks): ModuleList(\n",
       "                (0): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (2): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (4): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (5): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (6): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (7): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (8): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (9): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (10): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (11): SwinTransformerBlock(\n",
       "                  dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=512, window_size=(8, 8), num_heads=16\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): PatchMerging(\n",
       "                input_resolution=(16, 16), dim=512\n",
       "                (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "                (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (3): BasicLayer(\n",
       "              dim=1024, input_resolution=(8, 8), depth=2\n",
       "              (blocks): ModuleList(\n",
       "                (0-1): 2 x SwinTransformerBlock(\n",
       "                  dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                  (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attn): WindowAttention(\n",
       "                    dim=1024, window_size=(8, 8), num_heads=32\n",
       "                    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath()\n",
       "                  (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (mlp): Mlp(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "          (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "          (tscam_conv): Conv2d(1024, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "        )\n",
       "        (audio_transform): MLPLayers(\n",
       "          (nonlin): ReLU()\n",
       "          (sequential): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (audio_projection): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (projector): Sequential(\n",
       "      (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (video_model): VideoModel(\n",
       "    (encoder): VideoMAEModel(\n",
       "      (embeddings): VideoMAEEmbeddings(\n",
       "        (patch_embeddings): VideoMAEPatchEmbeddings(\n",
       "          (projection): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "        )\n",
       "      )\n",
       "      (encoder): VideoMAEEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x VideoMAELayer(\n",
       "            (attention): VideoMAEAttention(\n",
       "              (attention): VideoMAESelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): VideoMAESelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): VideoMAEIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): VideoMAEOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (projector): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=768, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimodel = TriModel(EMB_SIZE, BPE_VOCAB_SIZE, AUDIO_MODEL_KEY, AUDIO_MODEL_PATH, VIDEO_MODEL_KEY).to('cpu')\n",
    "trimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ee885fc-30bf-42f2-9009-85b844aef7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_emb', 'audio_emb', 'video_emb'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embeds = trimodel(*sample_batch.values())\n",
    "\n",
    "embeds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "094881d4-11e3-43fa-add1-91861b639e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 300]), torch.Size([2, 300]), torch.Size([2, 300]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds['text_emb'].shape, embeds['audio_emb'].shape, embeds['video_emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7d20a36-9366-41a6-9673-34f507b0cdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params\n",
      "text model: 3090900\n",
      "audio model: 73892229\n",
      "video model: 86459436\n",
      "tri model: 163442565\n"
     ]
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    n_params = 0\n",
    "    for p in model.parameters():\n",
    "        n_params += p.numel()\n",
    "    \n",
    "    return n_params\n",
    "\n",
    "print('# params')\n",
    "print('text model:', get_n_params(trimodel.text_model))\n",
    "print('audio model:', get_n_params(trimodel.audio_model))\n",
    "print('video model:', get_n_params(trimodel.video_model))\n",
    "print('tri model:', get_n_params(trimodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59ae1387-b166-478a-a023-8b613d725b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5122, 0.2314, 0.9860],\n",
       "        [0.6360, 0.8131, 0.1592]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2,3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "142bad19-acaf-4537-ac4d-0e5466cc1799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1c33030-944a-44f1-aa63-f8c43fcbe116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0067)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()(\n",
    "    torch.tensor([[5.0, 0.0],\n",
    "                  [0.0, 5.0]]),\n",
    "    torch.tensor([0, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b843f2d9-cc92-4ed2-93b2-cc2a4aec9ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss()(\n",
    "    torch.tensor([[0.0, 0.0],\n",
    "                  [0.0, 0.0]]),\n",
    "    torch.tensor([0, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dac6e65-88d9-489f-95fa-66a72c660159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(t, p=2, dim=1):\n",
    "    t = t / t.norm(p=p, dim=dim).unsqueeze(1)\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def contrastive_loss(emb1, emb2):\n",
    "    prods = emb1.matmul(emb2.T)\n",
    "    labels = torch.arange(emb1.shape[0]).to(emb1.device)\n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    loss1 = loss_func(prods, labels)\n",
    "    loss2 = loss_func(prods.T, labels)\n",
    "    loss = loss1 + loss2\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def trimodal_contrastive_objective(embeds):\n",
    "    cl = contrastive_loss\n",
    "    te = embeds['text_emb']\n",
    "    ae = embeds['audio_emb']\n",
    "    ve = embeds['video_emb']\n",
    "    \n",
    "    trimodal_loss = cl(te, ae) + cl(te, ve) + cl(ae, ve)\n",
    "    \n",
    "    return trimodal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9023fe4e-d5c4-4649-a81c-a3fbd0d2d785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.2661)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimodal_contrastive_objective(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02820130-0600-4896-99a7-b10ac033a06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
