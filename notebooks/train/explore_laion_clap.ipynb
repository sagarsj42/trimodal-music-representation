{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1b1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /scratch/sagarsj42\n",
    "\n",
    "import os\n",
    "os.chdir('/scratch/sagarsj42')\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/sagarsj42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82274da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███████████████| 232k/232k [00:00<00:00, 605kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████████| 28.0/28.0 [00:00<00:00, 2.66kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█████████████████| 570/570 [00:00<00:00, 407kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████████| 899k/899k [00:00<00:00, 2.43MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███████████████| 456k/456k [00:00<00:00, 814kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█████████████████| 481/481 [00:00<00:00, 265kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████████| 899k/899k [00:00<00:00, 4.68MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████████| 456k/456k [00:00<00:00, 1.23MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█████████████| 1.72k/1.72k [00:00<00:00, 861kB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import laion_clap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b48ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-05 21:48:55--  https://huggingface.co/lukewys/laion_clap/resolve/main/music_audioset_epoch_15_esc_90.14.pt\n",
      "Resolving huggingface.co (huggingface.co)... 108.158.46.32, 108.158.46.90, 108.158.46.5, ...\n",
      "Connecting to huggingface.co (huggingface.co)|108.158.46.32|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/bd/48/bd4853aeff7fe8c507daac22cffef84fcbb89a75ded88f90cfcd47c280becc58/fae3e9c087f2909c28a09dc31c8dfcdacbc42ba44c70e972b58c1bd1caf6dedd?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27music_audioset_epoch_15_esc_90.14.pt%3B+filename%3D%22music_audioset_epoch_15_esc_90.14.pt%22%3B&Expires=1686241135&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2JkLzQ4L2JkNDg1M2FlZmY3ZmU4YzUwN2RhYWMyMmNmZmVmODRmY2JiODlhNzVkZWQ4OGY5MGNmY2Q0N2MyODBiZWNjNTgvZmFlM2U5YzA4N2YyOTA5YzI4YTA5ZGMzMWM4ZGZjZGFjYmM0MmJhNDRjNzBlOTcyYjU4YzFiZDFjYWY2ZGVkZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODYyNDExMzV9fX1dfQ__&Signature=E522Rue%7EIFFQtb5PE4QDN1HtRl2xnHVjkkMyYkLMKNszsraR3lYqiSXOnZoj-PQHC34494cLH8Ay2miFc3BOjKraNB8VNCzat6wvicKiZ9BIxmFnJkp9Q3Ga8387KekreSpfHlbz64tQ%7EE7atKi0quwO%7EjUuHm5chs1LHPKYk6gY-V7vMEtx9eXdZhMbjVPdNleQ4n%7E94nlN7EUo7av3Q9e%7E665vD5WbulpP9x--Mi-ly6K9FWjjwRSJLkKgJL2BSCwgzYjQLbbgNKomG0YNaQRGoZhx42qPc%7Eyx2BMlpD-UnszD8YhiaYVPv8YBXD7PEGliUNSnVfN3hfoqWlGdDg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-06-05 21:48:55--  https://cdn-lfs.huggingface.co/repos/bd/48/bd4853aeff7fe8c507daac22cffef84fcbb89a75ded88f90cfcd47c280becc58/fae3e9c087f2909c28a09dc31c8dfcdacbc42ba44c70e972b58c1bd1caf6dedd?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27music_audioset_epoch_15_esc_90.14.pt%3B+filename%3D%22music_audioset_epoch_15_esc_90.14.pt%22%3B&Expires=1686241135&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2JkLzQ4L2JkNDg1M2FlZmY3ZmU4YzUwN2RhYWMyMmNmZmVmODRmY2JiODlhNzVkZWQ4OGY5MGNmY2Q0N2MyODBiZWNjNTgvZmFlM2U5YzA4N2YyOTA5YzI4YTA5ZGMzMWM4ZGZjZGFjYmM0MmJhNDRjNzBlOTcyYjU4YzFiZDFjYWY2ZGVkZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODYyNDExMzV9fX1dfQ__&Signature=E522Rue%7EIFFQtb5PE4QDN1HtRl2xnHVjkkMyYkLMKNszsraR3lYqiSXOnZoj-PQHC34494cLH8Ay2miFc3BOjKraNB8VNCzat6wvicKiZ9BIxmFnJkp9Q3Ga8387KekreSpfHlbz64tQ%7EE7atKi0quwO%7EjUuHm5chs1LHPKYk6gY-V7vMEtx9eXdZhMbjVPdNleQ4n%7E94nlN7EUo7av3Q9e%7E665vD5WbulpP9x--Mi-ly6K9FWjjwRSJLkKgJL2BSCwgzYjQLbbgNKomG0YNaQRGoZhx42qPc%7Eyx2BMlpD-UnszD8YhiaYVPv8YBXD7PEGliUNSnVfN3hfoqWlGdDg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.161.229.13, 18.161.229.125, 18.161.229.99, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.161.229.13|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2352471003 (2.2G) [binary/octet-stream]\n",
      "Saving to: ‘music_audioset_epoch_15_esc_90.14.pt’\n",
      "\n",
      "music_audioset_epoc 100%[===================>]   2.19G  44.3MB/s    in 58s     \n",
      "\n",
      "2023-06-05 21:49:54 (38.5 MB/s) - ‘music_audioset_epoch_15_esc_90.14.pt’ saved [2352471003/2352471003]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/lukewys/laion_clap/resolve/main/music_audioset_epoch_15_esc_90.14.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e579b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'music_audioset_epoch_15_esc_90.14.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7db2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For quantization\n",
    "def int16_to_float32(x):\n",
    "    return (x / 32767.0).astype(np.float32)\n",
    "\n",
    "def float32_to_int16(x):\n",
    "    x = np.clip(x, a_min=-1., a_max=1.)\n",
    "    return (x * 32767.).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2532c734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Downloading pytorch_model.bin: 100%|████████████████████| 501M/501M [00:11<00:00, 42.8MB/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLAP_Module(\n",
       "  (model): CLAP(\n",
       "    (audio_branch): HTSAT_Swin_Transformer(\n",
       "      (spectrogram_extractor): Spectrogram(\n",
       "        (stft): STFT(\n",
       "          (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "          (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (logmel_extractor): LogmelFilterBank()\n",
       "      (spec_augmenter): SpecAugmentation(\n",
       "        (time_dropper): DropStripes()\n",
       "        (freq_dropper): DropStripes()\n",
       "      )\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): BasicLayer(\n",
       "          dim=128, input_resolution=(64, 64), depth=2\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinTransformerBlock(\n",
       "              dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=128, window_size=(8, 8), num_heads=4\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=128, window_size=(8, 8), num_heads=4\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            input_resolution=(64, 64), dim=128\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicLayer(\n",
       "          dim=256, input_resolution=(32, 32), depth=2\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinTransformerBlock(\n",
       "              dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=256, window_size=(8, 8), num_heads=8\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=256, window_size=(8, 8), num_heads=8\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            input_resolution=(32, 32), dim=256\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicLayer(\n",
       "          dim=512, input_resolution=(16, 16), depth=12\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (6): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (7): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (8): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (9): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (10): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (11): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            input_resolution=(16, 16), dim=512\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): BasicLayer(\n",
       "          dim=1024, input_resolution=(8, 8), depth=2\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinTransformerBlock(\n",
       "              dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=1024, window_size=(8, 8), num_heads=32\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=1024, window_size=(8, 8), num_heads=32\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "      (tscam_conv): Conv2d(1024, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "    )\n",
       "    (text_branch): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (text_transform): MLPLayers(\n",
       "      (nonlin): ReLU()\n",
       "      (sequential): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (text_projection): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (audio_transform): MLPLayers(\n",
       "      (nonlin): ReLU()\n",
       "      (sequential): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (audio_projection): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = laion_clap.CLAP_Module(enable_fusion=False, amodel='HTSAT-base')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430eb23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the specified checkpoint music_audioset_epoch_15_esc_90.14.pt from users.\n",
      "Load Checkpoint...\n",
      "logit_scale_a \t Loaded\n",
      "logit_scale_t \t Loaded\n",
      "audio_branch.spectrogram_extractor.stft.conv_real.weight \t Loaded\n",
      "audio_branch.spectrogram_extractor.stft.conv_imag.weight \t Loaded\n",
      "audio_branch.logmel_extractor.melW \t Loaded\n",
      "audio_branch.bn0.weight \t Loaded\n",
      "audio_branch.bn0.bias \t Loaded\n",
      "audio_branch.patch_embed.proj.weight \t Loaded\n",
      "audio_branch.patch_embed.proj.bias \t Loaded\n",
      "audio_branch.patch_embed.norm.weight \t Loaded\n",
      "audio_branch.patch_embed.norm.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.0.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.0.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.0.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.1.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.1.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.1.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.6.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.6.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.6.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.6.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.6.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.6.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.6.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.6.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.6.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.6.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.6.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.6.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.6.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.7.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.7.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.7.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.7.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.7.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.7.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.7.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.7.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.7.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.7.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.7.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.7.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.7.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.8.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.8.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.8.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.8.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.8.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.8.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.8.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.8.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.8.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.8.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.8.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.8.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.8.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.9.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.9.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.9.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.9.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.9.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.9.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.9.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.9.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.9.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.9.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.9.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.9.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.9.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.10.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.10.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.10.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.10.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.10.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.10.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.10.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.10.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.10.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.10.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.10.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.10.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.10.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.11.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.11.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.11.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.11.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.11.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.11.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.11.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.11.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.11.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.11.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.11.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.11.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.11.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.2.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.2.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.norm.weight \t Loaded\n",
      "audio_branch.norm.bias \t Loaded\n",
      "audio_branch.tscam_conv.weight \t Loaded\n",
      "audio_branch.tscam_conv.bias \t Loaded\n",
      "audio_branch.head.weight \t Loaded\n",
      "audio_branch.head.bias \t Loaded\n",
      "text_branch.embeddings.word_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.position_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.token_type_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.LayerNorm.weight \t Loaded\n",
      "text_branch.embeddings.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.0.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.0.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.1.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.1.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.2.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.2.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.3.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.3.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.4.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.4.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.5.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.5.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.6.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.6.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.7.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.7.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.8.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.8.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.9.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.9.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.10.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.10.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.11.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.11.output.LayerNorm.bias \t Loaded\n",
      "text_branch.pooler.dense.weight \t Loaded\n",
      "text_branch.pooler.dense.bias \t Loaded\n",
      "text_transform.sequential.0.weight \t Loaded\n",
      "text_transform.sequential.0.bias \t Loaded\n",
      "text_transform.sequential.3.weight \t Loaded\n",
      "text_transform.sequential.3.bias \t Loaded\n",
      "text_projection.0.weight \t Loaded\n",
      "text_projection.0.bias \t Loaded\n",
      "text_projection.2.weight \t Loaded\n",
      "text_projection.2.bias \t Loaded\n",
      "audio_transform.sequential.0.weight \t Loaded\n",
      "audio_transform.sequential.0.bias \t Loaded\n",
      "audio_transform.sequential.3.weight \t Loaded\n",
      "audio_transform.sequential.3.bias \t Loaded\n",
      "audio_projection.0.weight \t Loaded\n",
      "audio_projection.0.bias \t Loaded\n",
      "audio_projection.2.weight \t Loaded\n",
      "audio_projection.2.bias \t Loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLAP_Module(\n",
       "  (model): CLAP(\n",
       "    (audio_branch): HTSAT_Swin_Transformer(\n",
       "      (spectrogram_extractor): Spectrogram(\n",
       "        (stft): STFT(\n",
       "          (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "          (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(480,), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (logmel_extractor): LogmelFilterBank()\n",
       "      (spec_augmenter): SpecAugmentation(\n",
       "        (time_dropper): DropStripes()\n",
       "        (freq_dropper): DropStripes()\n",
       "      )\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): BasicLayer(\n",
       "          dim=128, input_resolution=(64, 64), depth=2\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinTransformerBlock(\n",
       "              dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=128, window_size=(8, 8), num_heads=4\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              dim=128, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=128, window_size=(8, 8), num_heads=4\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            input_resolution=(64, 64), dim=128\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicLayer(\n",
       "          dim=256, input_resolution=(32, 32), depth=2\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinTransformerBlock(\n",
       "              dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=256, window_size=(8, 8), num_heads=8\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              dim=256, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=256, window_size=(8, 8), num_heads=8\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            input_resolution=(32, 32), dim=256\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicLayer(\n",
       "          dim=512, input_resolution=(16, 16), depth=12\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (6): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (7): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (8): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (9): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (10): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (11): SwinTransformerBlock(\n",
       "              dim=512, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=512, window_size=(8, 8), num_heads=16\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            input_resolution=(16, 16), dim=512\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): BasicLayer(\n",
       "          dim=1024, input_resolution=(8, 8), depth=2\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinTransformerBlock(\n",
       "              dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=1024, window_size=(8, 8), num_heads=32\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                dim=1024, window_size=(8, 8), num_heads=32\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): DropPath()\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "      (tscam_conv): Conv2d(1024, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "    )\n",
       "    (text_branch): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (text_transform): MLPLayers(\n",
       "      (nonlin): ReLU()\n",
       "      (sequential): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (text_projection): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (audio_transform): MLPLayers(\n",
       "      (nonlin): ReLU()\n",
       "      (sequential): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (audio_projection): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_ckpt(model_path)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c895be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = [\n",
    "    '/home2/sagarsj42/yt8m/data/sample.wav'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a1d340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (1, 512))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb = model.get_audio_embedding_from_filelist(x=audio_file, use_tensor=False)\n",
    "\n",
    "type(audio_emb), audio_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c6847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05279794, -0.05380071, -0.08961916, -0.00964758, -0.0385212 ,\n",
       "        -0.00467488,  0.05111531, -0.02370409, -0.01228538, -0.0250142 ,\n",
       "        -0.04035574, -0.04503557, -0.00160808, -0.02086216,  0.00052674,\n",
       "        -0.00241546,  0.0735217 ,  0.05885008, -0.00421781,  0.00917581]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb[:, -20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c86d8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([1, 512]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb = model.get_audio_embedding_from_filelist(x=audio_file, use_tensor=True)\n",
    "\n",
    "type(audio_emb), audio_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "303b29fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d93d9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " (1609422,),\n",
       " array([-0.03420503, -0.030711  , -0.02740682, -0.02452059, -0.02223679,\n",
       "        -0.02066216, -0.0198038 , -0.01956397, -0.01975277, -0.02011684,\n",
       "        -0.02037902, -0.02028223, -0.01962992, -0.01831628, -0.0163413 ,\n",
       "        -0.0138084 , -0.01090577, -0.00787481, -0.00497164, -0.00242835],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data, _ = librosa.load(audio_file[0], sr=48000)\n",
    "\n",
    "type(audio_data), audio_data.shape, audio_data[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647c65d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1609422),\n",
       " array([-0.03420503, -0.030711  , -0.02740682, -0.02452059, -0.02223679,\n",
       "        -0.02066216, -0.0198038 , -0.01956397, -0.01975277, -0.02011684,\n",
       "        -0.02037902, -0.02028223, -0.01962992, -0.01831628, -0.0163413 ,\n",
       "        -0.0138084 , -0.01090577, -0.00787481, -0.00497164, -0.00242835],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data = audio_data.reshape(1, -1)\n",
    "\n",
    "audio_data.shape, audio_data[0, -20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b12c3b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio_data_q \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_numpy(int16_to_float32(float32_to_int16(audio_data)))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      3\u001b[0m audio_data_q\u001b[38;5;241m.\u001b[39mdtype, audio_data_q[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "audio_data_q = torch.from_numpy(int16_to_float32(float32_to_int16(audio_data))).float()\n",
    "\n",
    "audio_data_q.dtype, audio_data_q[0, -20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e36d108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]),\n",
       " tensor([-0.0666, -0.0302, -0.0902, -0.0276, -0.0396, -0.0089,  0.0281, -0.0264,\n",
       "         -0.0277, -0.0249, -0.0295, -0.0435,  0.0135, -0.0239,  0.0038, -0.0061,\n",
       "          0.0741,  0.0464, -0.0107,  0.0182], device='cuda:0',\n",
       "        grad_fn=<SliceBackward0>),\n",
       " True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_embed = model.get_audio_embedding_from_data(audio_data_q, use_tensor=True)\n",
    "\n",
    "audio_embed.shape, audio_embed[0, -20:], audio_embed.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97f0d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor,\n",
       " torch.Size([2, 512]),\n",
       " tensor([[-0.1269, -0.0228,  0.0306,  0.0336, -0.0480, -0.0390,  0.0276, -0.0502,\n",
       "           0.0521,  0.0108],\n",
       "         [-0.0386, -0.0094, -0.0006,  0.0287,  0.0411, -0.0116,  0.0490, -0.0078,\n",
       "          -0.0297,  0.1238]], device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = ['Some sample music piece.', 'dog whistle']\n",
    "text_embed = model.get_text_embedding(text_data, use_tensor=True)\n",
    "\n",
    "type(text_embed), text_embed.shape, text_embed[:, -10:], text_embed.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af1758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
