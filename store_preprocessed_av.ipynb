{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/scratch/sagarsj42')\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/sagarsj42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home2/sagarsj42/miniconda3/envs/video/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import VideoMAEImageProcessor, VideoMAEConfig\n",
    "\n",
    "import pytorchvideo.data\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    UniformTemporalSubsample,\n",
    "    Normalize\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    Resize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INFO_DIR = './yt8m-clips-dataset-info'\n",
    "CLIP_INFO_FILENAME = 'clip-info.jsonl'\n",
    "VID_INFO_FILENAME = 'video-info.jsonl'\n",
    "AUDIO_CLIPS_DIR = './yt8m-audio-clips'\n",
    "VIDEO_CLIPS_DIR = './yt8m-video-clips'\n",
    "AUDIO_FEATURES_DIR = './yt8m-audio-features'\n",
    "VIDEO_FEATURES_DIR = './yt8m-video-features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = 'MCG-NJU/videomae-base'\n",
    "clip_duration = 8.0\n",
    "split = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int16_to_float32(x):\n",
    "    return (x / 32767.0).astype(np.float32)\n",
    "\n",
    "\n",
    "def float32_to_int16(x):\n",
    "    x = np.clip(x, a_min=-1., a_max=1.)\n",
    "    return (x * 32767.).astype(np.int16)\n",
    "\n",
    "\n",
    "def print_video_info(video):\n",
    "    for k in video:\n",
    "        if k == 'video':\n",
    "            print(k, video[k].shape)\n",
    "        else:\n",
    "            print(k, video[k])\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 461 entries, 0 to 460\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   vid          461 non-null    object \n",
      " 1   n_clips      461 non-null    int64  \n",
      " 2   audio_dur    461 non-null    float64\n",
      " 3   video_dur    461 non-null    float64\n",
      " 4   split        461 non-null    object \n",
      " 5   labels       461 non-null    object \n",
      " 6   title        461 non-null    object \n",
      " 7   description  461 non-null    object \n",
      " 8   tags         461 non-null    object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 32.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid</th>\n",
       "      <th>n_clips</th>\n",
       "      <th>audio_dur</th>\n",
       "      <th>video_dur</th>\n",
       "      <th>split</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZKBM2XCWfo8</td>\n",
       "      <td>28</td>\n",
       "      <td>224.816</td>\n",
       "      <td>224.69</td>\n",
       "      <td>test</td>\n",
       "      <td>[Piano, Pianist, Musical keyboard, Electronic ...</td>\n",
       "      <td>星から降る金  /ミュージカル【モーツァルト！】より カラオケ  ピアノ伴奏[フルート]</td>\n",
       "      <td>フルーティストのmkharu2さんとコラボさせていただきました♪ ぜひご覧ください！http...</td>\n",
       "      <td>新規プロジェクト</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gOwJkB7AJ6Y</td>\n",
       "      <td>55</td>\n",
       "      <td>439.287</td>\n",
       "      <td>439.21</td>\n",
       "      <td>test</td>\n",
       "      <td>[Concert, Musician, Musical ensemble, Drum kit...</td>\n",
       "      <td>Bill Ward Band - It's Alright - live 1997</td>\n",
       "      <td>Rearranged, but recognizable and quite good.</td>\n",
       "      <td>Bill Ward (Musical Artist),it's alright live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SXbvwzurIRA</td>\n",
       "      <td>26</td>\n",
       "      <td>205.032</td>\n",
       "      <td>204.88</td>\n",
       "      <td>test</td>\n",
       "      <td>[Musician, Choir]</td>\n",
       "      <td>Nederland Zingt: Ik bouw op U</td>\n",
       "      <td>Op onze God kunnen wij bouwen. Daar worden wij...</td>\n",
       "      <td>Nederland Zingt,NZD,NZ,NeZi,Christelijke muzie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DerkdSwHqT0</td>\n",
       "      <td>26</td>\n",
       "      <td>209.200</td>\n",
       "      <td>209.20</td>\n",
       "      <td>test</td>\n",
       "      <td>[Music video]</td>\n",
       "      <td>Plain White T’s – Pause (Official Lyrics video...</td>\n",
       "      <td>Sing along to Pause, the brand new single from...</td>\n",
       "      <td>lipton,lipton ice tea,lipton iced tea,ice tea,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMrgYXKfZC0</td>\n",
       "      <td>28</td>\n",
       "      <td>222.447</td>\n",
       "      <td>222.29</td>\n",
       "      <td>test</td>\n",
       "      <td>[Music video]</td>\n",
       "      <td>EXO - HURT [FANMADE] MV</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vid  n_clips  audio_dur  video_dur split  \\\n",
       "0  ZKBM2XCWfo8       28    224.816     224.69  test   \n",
       "1  gOwJkB7AJ6Y       55    439.287     439.21  test   \n",
       "2  SXbvwzurIRA       26    205.032     204.88  test   \n",
       "3  DerkdSwHqT0       26    209.200     209.20  test   \n",
       "4  PMrgYXKfZC0       28    222.447     222.29  test   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [Piano, Pianist, Musical keyboard, Electronic ...   \n",
       "1  [Concert, Musician, Musical ensemble, Drum kit...   \n",
       "2                                  [Musician, Choir]   \n",
       "3                                      [Music video]   \n",
       "4                                      [Music video]   \n",
       "\n",
       "                                               title  \\\n",
       "0       星から降る金  /ミュージカル【モーツァルト！】より カラオケ  ピアノ伴奏[フルート]   \n",
       "1          Bill Ward Band - It's Alright - live 1997   \n",
       "2                      Nederland Zingt: Ik bouw op U   \n",
       "3  Plain White T’s – Pause (Official Lyrics video...   \n",
       "4                            EXO - HURT [FANMADE] MV   \n",
       "\n",
       "                                         description  \\\n",
       "0  フルーティストのmkharu2さんとコラボさせていただきました♪ ぜひご覧ください！http...   \n",
       "1       Rearranged, but recognizable and quite good.   \n",
       "2  Op onze God kunnen wij bouwen. Daar worden wij...   \n",
       "3  Sing along to Pause, the brand new single from...   \n",
       "4                                                      \n",
       "\n",
       "                                                tags  \n",
       "0                                           新規プロジェクト  \n",
       "1       Bill Ward (Musical Artist),it's alright live  \n",
       "2  Nederland Zingt,NZD,NZ,NeZi,Christelijke muzie...  \n",
       "3  lipton,lipton ice tea,lipton iced tea,ice tea,...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_df = pd.read_json(os.path.join(DATASET_INFO_DIR, split, VID_INFO_FILENAME), lines=True)\n",
    "\n",
    "print(vid_df.info())\n",
    "\n",
    "vid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14806 entries, 0 to 14805\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   vid              14806 non-null  object \n",
      " 1   clip_no          14806 non-null  int64  \n",
      " 2   audio_clip_name  14806 non-null  object \n",
      " 3   audio_clip_dur   14806 non-null  float64\n",
      " 4   video_clip_name  14806 non-null  object \n",
      " 5   video_clip_dur   14806 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 694.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid</th>\n",
       "      <th>clip_no</th>\n",
       "      <th>audio_clip_name</th>\n",
       "      <th>audio_clip_dur</th>\n",
       "      <th>video_clip_name</th>\n",
       "      <th>video_clip_dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZKBM2XCWfo8</td>\n",
       "      <td>21</td>\n",
       "      <td>ZKBM2XCWfo8-audio-21.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ZKBM2XCWfo8-video-21.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZKBM2XCWfo8</td>\n",
       "      <td>20</td>\n",
       "      <td>ZKBM2XCWfo8-audio-20.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ZKBM2XCWfo8-video-20.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZKBM2XCWfo8</td>\n",
       "      <td>22</td>\n",
       "      <td>ZKBM2XCWfo8-audio-22.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ZKBM2XCWfo8-video-22.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZKBM2XCWfo8</td>\n",
       "      <td>23</td>\n",
       "      <td>ZKBM2XCWfo8-audio-23.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ZKBM2XCWfo8-video-23.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZKBM2XCWfo8</td>\n",
       "      <td>27</td>\n",
       "      <td>ZKBM2XCWfo8-audio-27.mp3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ZKBM2XCWfo8-video-27.mp4</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vid  clip_no           audio_clip_name  audio_clip_dur  \\\n",
       "0  ZKBM2XCWfo8       21  ZKBM2XCWfo8-audio-21.mp3             8.0   \n",
       "1  ZKBM2XCWfo8       20  ZKBM2XCWfo8-audio-20.mp3             8.0   \n",
       "2  ZKBM2XCWfo8       22  ZKBM2XCWfo8-audio-22.mp3             8.0   \n",
       "3  ZKBM2XCWfo8       23  ZKBM2XCWfo8-audio-23.mp3             8.0   \n",
       "4  ZKBM2XCWfo8       27  ZKBM2XCWfo8-audio-27.mp3             8.0   \n",
       "\n",
       "            video_clip_name  video_clip_dur  \n",
       "0  ZKBM2XCWfo8-video-21.mp4            8.01  \n",
       "1  ZKBM2XCWfo8-video-20.mp4            8.01  \n",
       "2  ZKBM2XCWfo8-video-22.mp4            8.01  \n",
       "3  ZKBM2XCWfo8-video-23.mp4            8.01  \n",
       "4  ZKBM2XCWfo8-video-27.mp4            8.01  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_df = pd.read_json(os.path.join(DATASET_INFO_DIR, split, CLIP_INFO_FILENAME), lines=True)\n",
    "\n",
    "print(clip_df.info())\n",
    "\n",
    "clip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoMAEImageProcessor {\n",
       "  \"crop_size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  },\n",
       "  \"do_center_crop\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"VideoMAEFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"VideoMAEImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor = VideoMAEImageProcessor.from_pretrained(model_key)\n",
    "\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoMAEConfig {\n",
       "  \"architectures\": [\n",
       "    \"VideoMAEForPreTraining\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.0,\n",
       "  \"decoder_hidden_size\": 384,\n",
       "  \"decoder_intermediate_size\": 1536,\n",
       "  \"decoder_num_attention_heads\": 6,\n",
       "  \"decoder_num_hidden_layers\": 4,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.0,\n",
       "  \"hidden_size\": 768,\n",
       "  \"image_size\": 224,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"model_type\": \"videomae\",\n",
       "  \"norm_pix_loss\": true,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_channels\": 3,\n",
       "  \"num_frames\": 16,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"patch_size\": 16,\n",
       "  \"qkv_bias\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.29.2\",\n",
       "  \"tubelet_size\": 2,\n",
       "  \"use_mean_pooling\": false\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = VideoMAEConfig.from_pretrained(model_key)\n",
    "\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mean = image_processor.image_mean\n",
    "image_std = image_processor.image_std\n",
    "\n",
    "if 'shortest_edge' in image_processor.size:\n",
    "    height = width = image_processor.size['shortest_edge']\n",
    "else:\n",
    "    height = image_processor.size['height']\n",
    "    width = image_processor.size['width']\n",
    "resize_to = (height, width)\n",
    "\n",
    "num_frames_to_sample = model_config.num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Compose(\n",
       "     <pytorchvideo.transforms.transforms.ApplyTransformToKey object at 0x7f38a01f1a90>\n",
       " ),\n",
       " 16854)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_transform = Compose(\n",
    "    [\n",
    "        ApplyTransformToKey(\n",
    "            key='video',\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    UniformTemporalSubsample(num_frames_to_sample),\n",
    "                    Lambda(lambda x: x/255.0),\n",
    "                    Normalize(image_mean, image_std),\n",
    "                    Resize(resize_to)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "video_dataset = pytorchvideo.data.Ucf101(\n",
    "    data_path=os.path.join(VIDEO_CLIPS_DIR, split),\n",
    "    clip_sampler=pytorchvideo.data.make_clip_sampler('uniform', clip_duration),\n",
    "    decode_audio=False,\n",
    "    transform=video_transform\n",
    ")\n",
    "\n",
    "video_transform, video_dataset.num_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video torch.Size([3, 16, 224, 224])\n",
      "video_name IAfT-CBJD7E-video-24.mp4\n",
      "video_index 4398\n",
      "clip_index 0\n",
      "aug_index 0\n",
      "label 131\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(video_dataset))\n",
    "print_video_info(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289 ms ± 33.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "next(iter(video_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384001,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read each clip, dump librosa output\n",
    "row = clip_df.iloc[0]\n",
    "vid = row['vid']\n",
    "clip_no = row['clip_no']\n",
    "audio_clip_filename = row['audio_clip_name']\n",
    "audio_clip_filepath = os.path.join(AUDIO_CLIPS_DIR, split, vid, audio_clip_filename)\n",
    "audio_data, _ = librosa.load(audio_clip_filepath, sr=48000)\n",
    "\n",
    "audio_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.1 ms ± 62.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "audio_data, _ = librosa.load(audio_clip_filepath, sr=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(VIDEO_FEATURES_DIR, split), exist_ok=True)\n",
    "for i, video_sample in enumerate(iter(video_dataset)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    video_clip_filename = video_sample['video_name']\n",
    "    vid = video_clip_filename[:11]\n",
    "    video_frames = video_sample['video'].permute(1, 0, 2, 3).numpy().astype(np.float16)\n",
    "    \n",
    "    os.makedirs(os.path.join(VIDEO_FEATURES_DIR, split, vid), exist_ok=True)\n",
    "    video_features_filename = video_clip_filename[:-4].replace('-video-', '-vidfeat-') + '.npy'\n",
    "    np.save(os.path.join(VIDEO_FEATURES_DIR, split, vid, video_features_filename), video_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3, 224, 224)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(VIDEO_FEATURES_DIR, split, vid, video_features_filename)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616 µs ± 3.45 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.load(os.path.join(VIDEO_FEATURES_DIR, split, vid, video_features_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video_features(split):\n",
    "    video_dataset = pytorchvideo.data.Ucf101(\n",
    "        data_path=os.path.join(VIDEO_CLIPS_DIR, split),\n",
    "        clip_sampler=pytorchvideo.data.make_clip_sampler('uniform', clip_duration),\n",
    "        decode_audio=False,\n",
    "        transform=video_transform\n",
    "    )\n",
    "    \n",
    "    os.makedirs(os.path.join(VIDEO_FEATURES_DIR, split), exist_ok=True)\n",
    "    for i, video_sample in enumerate(iter(video_dataset)):\n",
    "        # if i > 1000:\n",
    "        #     break\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(split, i, 'videos')\n",
    "        video_clip_filename = video_sample['video_name']\n",
    "        vid = video_clip_filename[:11]\n",
    "        video_frames = video_sample['video'].permute(1, 0, 2, 3).numpy().astype(np.float16)\n",
    "\n",
    "        os.makedirs(os.path.join(VIDEO_FEATURES_DIR, split, vid), exist_ok=True)\n",
    "        video_features_filename = video_clip_filename[:-4].replace('-video-', '-vidfeat-') + '.npy'\n",
    "        np.save(os.path.join(VIDEO_FEATURES_DIR, split, vid, video_features_filename), video_frames)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data_splits = ['dev', 'test', 'train1', 'train2', 'train3', 'train4', 'train5']\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=7) as pool:\n",
    "    futures = (pool.submit(save_video_features, current_split) \n",
    "               for current_split in data_splits)\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "print('Time taken:', time.time() - start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio_features(split):\n",
    "    if 'train' in split:\n",
    "        clip_df = pd.read_json(os.path.join(DATASET_INFO_DIR, 'train', CLIP_INFO_FILENAME), lines=True)\n",
    "        vid_df = pd.read_json(os.path.join(DATASET_INFO_DIR, 'train', VID_INFO_FILENAME), lines=True)\n",
    "    else:\n",
    "        clip_df = pd.read_json(os.path.join(DATASET_INFO_DIR, split, CLIP_INFO_FILENAME), lines=True)\n",
    "        vid_df = pd.read_json(os.path.join(DATASET_INFO_DIR, split, VID_INFO_FILENAME), lines=True)\n",
    "    vids = vid_df[vid_df['split'] == split]['vid'].tolist()\n",
    "    os.makedirs(os.path.join(AUDIO_FEATURES_DIR, split), exist_ok=True)\n",
    "    \n",
    "    print(split, len(vids))\n",
    "    \n",
    "    for i, vid in enumerate(vids):\n",
    "        # if i > 0 and i > 50:\n",
    "        #     break\n",
    "        if i > 0 and i % 50 == 0:\n",
    "            print(split, i, 'audios')\n",
    "        audio_filenames = clip_df[clip_df['vid'] == vid]['audio_clip_name']\n",
    "        for clip_file_name in audio_filenames:\n",
    "            audio_clip_filepath = os.path.join(AUDIO_CLIPS_DIR, split, vid, clip_file_name)\n",
    "            audio_data, _ = librosa.load(audio_clip_filepath, sr=48000)\n",
    "            os.makedirs(os.path.join(AUDIO_FEATURES_DIR, split, vid), exist_ok=True)\n",
    "            audio_features_filename = clip_file_name[:-4].replace('-audio-', '-audfeat-') + '.npy'\n",
    "            np.save(os.path.join(AUDIO_FEATURES_DIR, split, vid, audio_features_filename), audio_data)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 461\n",
      "dev 499\n",
      "train3 958\n",
      "train1 903\n",
      "train5 1039\n",
      "train4 959\n",
      "train2 972\n",
      "train1 50 videos\n",
      "train2 50 videos\n",
      "train1 100 videos\n",
      "train3 50 videos\n",
      "train2 100 videos\n",
      "train1 150 videos\n",
      "train2 150 videos\n",
      "train1 200 videos\n",
      "train3 100 videos\n",
      "train1 250 videos\n",
      "train2 200 videos\n",
      "train3 150 videos\n",
      "train1 300 videos\n",
      "train2 250 videos\n",
      "train1 350 videos\n",
      "train3 200 videos\n",
      "train5 50 videos\n",
      "train4 50 videos\n",
      "train2 300 videos\n",
      "train1 400 videos\n",
      "train3 250 videos\n",
      "train1 450 videos\n",
      "train2 350 videos\n",
      "train4 100 videos\n",
      "train1 500 videos\n",
      "train5 100 videos\n",
      "train2 400 videos\n",
      "train3 300 videos\n",
      "train1 550 videos\n",
      "train2 450 videos\n",
      "train1 600 videos\n",
      "train3 350 videos\n",
      "train4 150 videos\n",
      "train2 500 videos\n",
      "train1 650 videos\n",
      "train5 150 videos\n",
      "train3 400 videos\n",
      "train1 700 videos\n",
      "train2 550 videos\n",
      "train4 200 videos\n",
      "train1 750 videos\n",
      "train3 450 videos\n",
      "train2 600 videos\n",
      "train1 800 videos\n",
      "train5 200 videos\n",
      "train2 650 videos\n",
      "train1 850 videos\n",
      "train4 250 videos\n",
      "train3 500 videos\n",
      "train1 900 videos\n",
      "train2 700 videos\n",
      "train3 550 videos\n",
      "train5 250 videos\n",
      "train4 300 videos\n",
      "train2 750 videos\n",
      "train3 600 videos\n",
      "train2 800 videos\n",
      "train5 300 videos\n",
      "train4 350 videos\n",
      "train3 650 videos\n",
      "train2 850 videos\n",
      "train2 900 videos\n",
      "train3 700 videos\n",
      "train4 400 videos\n",
      "train5 350 videos\n",
      "train2 950 videos\n",
      "train3 750 videos\n",
      "train4 450 videos\n",
      "train3 800 videos\n",
      "train5 400 videos\n",
      "train4 500 videos\n",
      "train3 850 videos\n",
      "train5 450 videos\n",
      "test 50 videos\n",
      "train3 900 videos\n",
      "train4 550 videos\n",
      "train3 950 videos\n",
      "train5 500 videos\n",
      "dev 50 videos\n",
      "train4 600 videos\n",
      "train5 550 videos\n",
      "train4 650 videos\n",
      "train5 600 videos\n",
      "train4 700 videos\n",
      "train5 650 videos\n",
      "train4 750 videos\n",
      "train5 700 videos\n",
      "train4 800 videos\n",
      "train4 850 videos\n",
      "train5 750 videos\n",
      "train4 900 videos\n",
      "train5 800 videos\n",
      "train4 950 videos\n",
      "train5 850 videos\n",
      "test 100 videos\n",
      "dev 100 videos\n",
      "train5 900 videos\n",
      "train5 950 videos\n",
      "test 150 videos\n",
      "train5 1000 videos\n",
      "dev 150 videos\n",
      "test 200 videos\n",
      "dev 200 videos\n",
      "dev 250 videos\n",
      "test 250 videos\n",
      "dev 300 videos\n",
      "test 300 videos\n",
      "dev 350 videos\n",
      "test 350 videos\n",
      "dev 400 videos\n",
      "test 400 videos\n",
      "test 450 videos\n",
      "dev 450 videos\n",
      "Time taken: 1881.948669910431 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_splits = ['dev', 'test', 'train1', 'train2', 'train3', 'train4', 'train5']\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=7) as pool:\n",
    "    futures = (pool.submit(save_audio_features, current_split) \n",
    "               for current_split in data_splits)\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "print('Time taken:', time.time() - start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
